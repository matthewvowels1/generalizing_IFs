{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d0ec6e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d8ec6e",
   "metadata": {},
   "source": [
    "## Summary of Results:\n",
    "\n",
    "$\\hat Q$ is the outcome estimator, $\\hat G$ is the propensity score estimator. Their respective columns tell us which estimators are use e.g. NN means a neural network was used.\n",
    "\n",
    "'Reduction' is the relative percent error reduction when compared against the plug-in estimator using the outcome model alone. The results are averages over 60 simulations.\n",
    "\n",
    "\n",
    "| Method | $\\hat Q$ | $\\hat G$ | Reduction $\\%$ | Rel. Error $\\%$ |\n",
    "| --- | --- | --- | --- |--- |\n",
    "| Naive | $NN$ | - |- |  4.059|\n",
    "| TMLE | $NN$ | $NN$ | 1.450 | 2.608 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e1217b",
   "metadata": {},
   "source": [
    "## Problem Setup:\n",
    "\n",
    "This example is taken from https://arxiv.org/abs/2107.00681 by Hines, Dukes, Diaz-Ordaz, and Vansteelandt (2021) and the empirical evaluation follows https://onlinelibrary.wiley.com/doi/full/10.1002/sim.7628 by Miguel Angel Luque-Fernandez, Michael Schomaker, Bernard Rachet, Mireille E. Schnitzer (2018).\n",
    "\n",
    "\n",
    "The following experiments are very similar to the ones in ATE.ipynb, but this time we will fit the estimators using a neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7049bda1",
   "metadata": {},
   "source": [
    "## 1. Define the DGP and some helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9f134282",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sigm(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def inv_sigm(x):\n",
    "    return np.log(x/(1-x))\n",
    "\n",
    "def generate_data(N, seed):\n",
    "    np.random.seed(seed=seed)\n",
    "    z1 = np.random.binomial(1, 0.5, (N,1))\n",
    "    z2 = np.random.binomial(1, 0.65, (N,1))\n",
    "    z3 = np.round(np.random.uniform(0, 4, (N,1)),3)\n",
    "    z4 = np.round(np.random.uniform(0, 5, (N,1)),3)\n",
    "    X = np.random.binomial(1, sigm(-0.4 + 0.2*z2 + 0.15*z3 + 0.2*z4 + 0.15*z2*z4), (N,1))\n",
    "    Y1 = np.random.binomial(1, sigm(-1 + 1 - 0.1*z1 + 0.3*z2 + 0.25*z3 + 0.2*z4 + 0.15*z2*z4), (N,1))\n",
    "    Y0 = np.random.binomial(1, sigm(-1 + 0 - 0.1*z1 + 0.3*z2 + 0.25*z3 + 0.2*z4 + 0.15*z2*z4), (N,1))\n",
    "    Y = Y1 * X + Y0 * (1-X)\n",
    "    Z = np.concatenate([z1,z2,z3,z4],1)\n",
    "    return Z, X, Y, Y1, Y0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed127b9",
   "metadata": {},
   "source": [
    "## 2. Define the Neural Network Objects/Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "be134faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "        m.bias.data.fill_(0.01)     \n",
    "\n",
    "class QNet(nn.Module):\n",
    "    def __init__(self, input_size, num_layers, layers_size, output_size, output_type, dropout):\n",
    "        super(QNet, self).__init__()      \n",
    "        \n",
    "        self.epsilon = nn.Parameter(torch.tensor([0.0]), requires_grad=True)\n",
    "        \n",
    "        layers = []\n",
    "        layers.extend([nn.Linear(input_size, layers_size), nn.ReLU()])\n",
    "        for i in range(num_layers-1):\n",
    "            layers.extend([nn.Linear(layers_size, layers_size), nn.ReLU(), nn.Dropout(p=dropout)])\n",
    "        self.net = nn.Sequential(*layers)\n",
    "        \n",
    "        pos_arm = []\n",
    "        pos_arm.extend([nn.Linear(layers_size, layers_size), nn.ReLU()])\n",
    "        pos_arm.extend([nn.Linear(layers_size, output_size)])     \n",
    "        \n",
    "        neg_arm = []\n",
    "        neg_arm.extend([nn.Linear(layers_size, layers_size), nn.ReLU()])\n",
    "        neg_arm.extend([nn.Linear(layers_size, output_size)])    \n",
    "        \n",
    "        if output_type == 'categorical':\n",
    "            pos_arm.append(nn.Sigmoid())\n",
    "            neg_arm.append(nn.Sigmoid())\n",
    "        elif output_type == 'continuous':\n",
    "            pass\n",
    "        self.pos_arm = nn.Sequential(*pos_arm)\n",
    "        self.neg_arm = nn.Sequential(*neg_arm)\n",
    "    \n",
    "        self.net.apply(init_weights) \n",
    "        self.neg_arm.apply(init_weights) \n",
    "        self.pos_arm.apply(init_weights) \n",
    "\n",
    "\n",
    "    def forward(self, X, Z):\n",
    "        \n",
    "        out = self.net(torch.cat([X,Z],1))\n",
    "        out0 = self.neg_arm(out)\n",
    "        out1 = self.pos_arm(out)\n",
    "        cond = X.bool()\n",
    "        return torch.where(cond, out1, out0)\n",
    "\n",
    "    \n",
    "    \n",
    "class GNet(nn.Module):\n",
    "    def __init__(self, input_size, num_layers, layers_size, output_size, output_type, dropout):\n",
    "        super(GNet, self).__init__()      \n",
    "        self.output_type = output_type\n",
    "        layers = []\n",
    "        layers.extend([nn.Linear(input_size, layers_size), nn.ReLU()])\n",
    "        for i in range(num_layers-1):\n",
    "            layers.extend([nn.Linear(layers_size, layers_size), nn.ReLU(), nn.Dropout(p=dropout)])\n",
    "        layers.extend([nn.Linear(layers_size, output_size)])\n",
    "\n",
    "        if output_type == 'categorical':\n",
    "            layers.append(nn.Sigmoid())\n",
    "        elif output_type == 'continuous':\n",
    "            pass\n",
    "        self.net = nn.Sequential(*layers)\n",
    "        self.net.apply(init_weights) \n",
    "        \n",
    "    def forward(self, Z):\n",
    "        if self.output_type == 'categorical':\n",
    "            out = (0.01 + self.net(Z))/1.02\n",
    "#             out = self.net(Z)\n",
    "        elif self.output_type == 'continuous':\n",
    "            out = self.net(Z)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7283e3",
   "metadata": {},
   "source": [
    "## 3. Create a Neural Network training class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "696557f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit_(p):\n",
    "    return torch.log(p / (1 - p))\n",
    "\n",
    "class Trainer(object):\n",
    "    def __init__(self, net, net_type='Q', beta=1.0, outcome_type='categorical', iterations=None, batch_size=None, test_iter=None, lr=None):\n",
    "        self.net_type = net_type\n",
    "        self.net = net\n",
    "        self.beta = beta\n",
    "        self.iterations = iterations\n",
    "        self.batch_size = batch_size\n",
    "        self.test_iter = test_iter\n",
    "        self.outcome_type = outcome_type\n",
    "        \n",
    "        if lr is not None:\n",
    "            self.optimizer = optim.SGD(self.net.parameters(), lr=lr, momentum=0.9, nesterov=True)\n",
    "        \n",
    "        self.bce_loss = nn.BCELoss(reduction='none')\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "    \n",
    "        \n",
    "    def train(self, x, y, z, x_pred=None):\n",
    "        \n",
    "        # create a small validation set\n",
    "        indices = np.arange(len(x))\n",
    "        np.random.shuffle(indices)\n",
    "        val_inds = indices[:len(x)//8]\n",
    "        train_inds = indices[len(x)//8:]\n",
    "        x_val, y_val, z_val = x[val_inds], y[val_inds], z[val_inds]\n",
    "        x_train, y_train, z_train = x[train_inds], y[train_inds], z[train_inds]\n",
    "        x_pred_train, x_pred_val = None, None\n",
    "        if self.net_type == 'Q':\n",
    "            x_pred_train, x_pred_val = x_pred[train_inds], x_pred[val_inds]\n",
    "        \n",
    "        indices = np.arange(len(x_train))\n",
    "        \n",
    "        train_losses = []\n",
    "        test_losses = []\n",
    "        epsilons = [] \n",
    "        best_model = None\n",
    "        best_model_test_loss = 1e10\n",
    "        best_early_stop_test_loss = 1e10\n",
    "        test_loss_window = []\n",
    "        window_length = 50  # number of measures of loss over which to determine early stopping\n",
    "        stopping_iteration = self.iterations  # initialise early stopping iter as the total iters\n",
    "        \n",
    "        for it in range(self.iterations):\n",
    "            inds = np.random.choice(indices, self.batch_size)\n",
    "            x_batch, y_batch, z_batch = x_train[inds], y_train[inds], z_train[inds]\n",
    "            \n",
    "            if self.net_type == 'Q':\n",
    "                x_pred_batch = x_pred_train[inds]\n",
    "                pred = self.net(x_batch, z_batch)\n",
    "                treg_loss = self.beta * self.treg(x_batch, x_pred_batch, y_batch, pred)\n",
    "                \n",
    "                if self.outcome_type == 'categorical':\n",
    "                    loss = self.bce_loss(pred, y_batch).mean()\n",
    "                else:\n",
    "                    loss = self.mse_loss(pred, y_batch)\n",
    "                    \n",
    "                loss += treg_loss\n",
    "                \n",
    "                \n",
    "            elif self.net_type == 'G':\n",
    "                pred = self.net(z_batch)\n",
    "                if self.outcome_type == 'categorical':\n",
    "                    loss = self.bce_loss(pred, x_batch).mean()\n",
    "                else:\n",
    "                    loss = self.mse_loss(pred, x_batch)\n",
    "\n",
    "            loss.backward(retain_graph=True if self.net_type == 'Q' else False)\n",
    "            self.optimizer.step()\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            \n",
    "            if (it % self.test_iter == 0) or (it == (self.iterations-1)):\n",
    "                self.net.eval()\n",
    "\n",
    "                if self.net_type == 'Q':\n",
    "                    pred = self.net(x_train[:800], z_train[:800])\n",
    "                    treg_loss = self.beta * self.treg(x_train[:800], x_pred_train[:800], y_train[:800], pred)\n",
    "                    epsilons.append(self.net.epsilon.detach().numpy()[0])\n",
    "\n",
    "                    if self.outcome_type == 'categorical':\n",
    "                        loss = self.bce_loss(pred, y_train[:800]).mean()\n",
    "                    else:\n",
    "                        loss = self.mse_loss(pred, y_train[:800])\n",
    "                    loss += treg_loss\n",
    "\n",
    "                elif self.net_type == 'G':\n",
    "                    pred = self.net(z_train[:800])\n",
    "                    if self.outcome_type == 'categorical':\n",
    "                        loss = self.bce_loss(pred, x_train[:800]).mean()\n",
    "                    else:\n",
    "                        loss = self.mse_loss(pred, x_train[:800])\n",
    "\n",
    "\n",
    "                train_losses.append(loss.item())\n",
    "\n",
    "                loss_test, _ = self.test(self.net, x_val, y_val, z_val, x_pred_val)\n",
    "                loss_test = loss_test.detach().numpy()\n",
    "                test_losses.append(loss_test.item())\n",
    "\n",
    "                self.net.train()\n",
    "   \n",
    "                # Early Stopping Code part 1\n",
    "                if len(test_loss_window) > window_length:  # reset window\n",
    "                    test_loss_window = [] \n",
    "                test_loss_window.append(loss_test)\n",
    "                # Early Stopping Code part 2\n",
    "                if len(test_loss_window) == window_length:  # if we have a complete window\n",
    "                    av_loss_window = np.mean(test_loss_window)  # take average\n",
    "                    if av_loss_window < best_early_stop_test_loss:\n",
    "                        best_early_stop_test_loss = av_loss_window\n",
    "                    else:\n",
    "                        print('Test loss window average ',av_loss_window, ' increasing, breaking loop at iter ', it)\n",
    "                        stopping_iteration = it\n",
    "                        break\n",
    "        \n",
    "                if (loss_test < best_model_test_loss):\n",
    "                    best_model_test_loss = loss_test\n",
    "                    best_model = self.net\n",
    "                \n",
    "        return train_losses, test_losses, stopping_iteration, best_model, best_model_test_loss, epsilons\n",
    "    \n",
    "    \n",
    "    def test(self, model, x, y, z, x_pred=None):\n",
    "        model.eval()\n",
    "        \n",
    "        if self.net_type == 'Q':\n",
    "            pred = model(x, z)\n",
    "            treg_loss = self.beta * self.treg(x, x_pred, y, pred)\n",
    "            if self.outcome_type == 'categorical':\n",
    "                loss = self.bce_loss(pred, y).mean()\n",
    "            else:\n",
    "                loss = self.mse_loss(pred, y)\n",
    "            loss += treg_loss\n",
    "\n",
    "        elif self.net_type == 'G':\n",
    "            pred = model(z)\n",
    "            if self.outcome_type == 'categorical':\n",
    "                loss = self.bce_loss(pred, x).mean()\n",
    "            else:\n",
    "                loss = self.mse_loss(pred, x)\n",
    "        \n",
    "        return loss, pred\n",
    "    \n",
    "    def treg(self, x, pred_x, y, pred_y):\n",
    "        pred_x = torch.clip(pred_x, 0.05, 0.99)\n",
    "        h = x / pred_x - (1 - x) / (1 - pred_x)\n",
    "        \n",
    "        if self.outcome_type == 'categorical':\n",
    "            y_pert = torch.sigmoid(logit_(p=pred_y) + self.net.epsilon * h)\n",
    "            t_reg = torch.sum(\n",
    "                    - y * torch.log(y_pert) - (1 - y) * torch.log(1 - y_pert))\n",
    "        elif self.outcome_type == 'continuous':\n",
    "            y_pert = pred_y + self.net.epsilon * h\n",
    "            t_reg = torch.sum((y - y_pert) ** 2)\n",
    "        return t_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e57e6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4e2e5e6",
   "metadata": {},
   "source": [
    "## 4. Create a hyperparameter tuning class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0658fcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tuner(object):\n",
    "    def __init__(self, x, y, z, trials, x_pred=None, net_type='Q', best_params=None):\n",
    "        self.net_type = net_type\n",
    "        self.best_params = best_params\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.z = z\n",
    "        self.x_pred = x_pred\n",
    "        self.trials = trials\n",
    "        self.test_iter = 5\n",
    "        self.best_params = best_params\n",
    "        self.net = None\n",
    "        self.best_model = None\n",
    "        \n",
    "    def tune(self):\n",
    "\n",
    "        output_type = 'categorical'\n",
    "        output_size = 1\n",
    "        \n",
    "        if self.net_type == 'Q':\n",
    "            input_size = z.shape[-1] + 1  # we will concatenate the treatment var inside the qnet class\n",
    "        elif self.net_type == 'G':\n",
    "            input_size = z.shape[-1] \n",
    "            \n",
    "        train_loss = []\n",
    "        val_loss = []\n",
    "        bs_ = []\n",
    "        iters_ = []\n",
    "        lr_ = []\n",
    "        stop_it_ = []   # list for early stopping iteration\n",
    "        layers_ = []\n",
    "        dropout_ = []\n",
    "        beta_ = []\n",
    "        layer_size_ = []\n",
    "        best_loss = 1e10\n",
    "        best_losses = []\n",
    "        epsilons_ = None\n",
    "        for trial in range(self.trials):\n",
    "            # sample hyper params and store the history\n",
    "            bs = np.random.randint(10,64) if self.best_params == None else self.best_params['batch_size']\n",
    "            bs_.append(bs)\n",
    "            iters = np.random.randint(15000,100000) if self.best_params == None else self.best_params['iters']\n",
    "            iters_.append(iters)\n",
    "            lr = np.random.uniform(0.0001, 0.01) if self.best_params == None else self.best_params['lr']\n",
    "            lr_.append(lr)\n",
    "            beta = np.random.uniform(0.001, 1.0) if self.best_params == None else self.best_params['beta']\n",
    "            beta_.append(beta)\n",
    "            layers = np.random.randint(2, 6) if self.best_params == None else self.best_params['layers']\n",
    "            layers_.append(layers)\n",
    "            dropout = np.random.uniform(0.1,0.5) if self.best_params == None else self.best_params['dropout']\n",
    "            dropout_.append(dropout)\n",
    "            layer_size = np.random.randint(4, 32) if self.best_params == None else self.best_params['layer_size']\n",
    "            layer_size_.append(layer_size)\n",
    "            print('======== Trial {} of {} ========='.format(trial, self.trials-1))\n",
    "            print('Batch size', bs, ' Iters', iters, ' Lr', lr, ' Layers', layers,\n",
    "                 ' Dropout', dropout, ' Layer Size', layer_size, 'beta', beta)\n",
    "\n",
    "            if self.net_type == 'Q':\n",
    "                self.net = QNet(input_size=input_size, num_layers=layers,\n",
    "                          layers_size=layer_size, output_size=output_size,\n",
    "                         output_type=output_type, dropout=dropout)\n",
    "            elif self.net_type == 'G': \n",
    "                self.net = GNet(input_size=input_size, num_layers=layers,\n",
    "                          layers_size=layer_size, output_size=output_size,\n",
    "                         output_type=output_type, dropout=dropout)\n",
    "\n",
    "            trainer = Trainer(net=self.net, net_type=self.net_type, beta=beta, outcome_type=output_type,\n",
    "                              iterations=iters, batch_size=bs, test_iter=self.test_iter, lr=lr)\n",
    "            train_loss_, val_loss_, stop_it, best_model, best_model_test_loss_, epsilons_ = trainer.train(self.x, self.y, self.z,\n",
    "                                                                                                         x_pred=self.x_pred)\n",
    "            \n",
    "            print('Best number of iterations: ', stop_it, 'compared with total:', iters)\n",
    "            stop_it_.append(stop_it)\n",
    "            train_loss.append(train_loss_[-1])\n",
    "            val_loss.append(val_loss_[-1])\n",
    "            best_losses.append(best_model_test_loss_)\n",
    "            \n",
    "            total_val_loss = val_loss_[-1]\n",
    "            \n",
    "            if best_model_test_loss_ < best_loss:\n",
    "                print('old loss:', best_loss)\n",
    "                print('new loss:', total_val_loss)\n",
    "                print('best model updated')\n",
    "                best_loss = best_model_test_loss_\n",
    "                self.best_model = best_model\n",
    "\n",
    "        tuning_dict = {'batch_size': bs_, 'layers':layers_, 'dropout':dropout_, 'beta':beta_,\n",
    "                      'layer_size':layer_size_,'lr':lr_, 'iters':iters_, 'stop_it': stop_it_,\n",
    "                      'train_loss':train_loss, 'val_loss':val_loss, 'best_model_test_loss':best_losses,\n",
    "                      }\n",
    "        \n",
    "        if self.net_type == 'G':\n",
    "            _, best_model_preds = trainer.test(self.best_model, self.x, self.y, self.z)\n",
    "        else:\n",
    "            best_model_preds = None\n",
    "        return tuning_dict, self.best_model, best_model_preds, epsilons_\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6fc57a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "129eeea7",
   "metadata": {},
   "source": [
    "## 5. Run Hyperparameter Search\n",
    "\n",
    "Now we have everything we need, we can initialize the neural networks, run hyperparameter search to identify the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8560a2ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Trial 0 of 1 =========\n",
      "Batch size 44  Iters 53624  Lr 0.000652378214512967  Layers 2  Dropout 0.3967010199864429  Layer Size 7 beta 0.8970822072505603\n",
      "Test loss window average  0.6359822  increasing, breaking loop at iter  4580\n",
      "Best number of iterations:  4580 compared with total: 53624\n",
      "old loss: 10000000000.0\n",
      "new loss: 0.6348485946655273\n",
      "best model updated\n",
      "======== Trial 1 of 1 =========\n",
      "Batch size 51  Iters 71133  Lr 0.0014992319941841922  Layers 4  Dropout 0.4170493203621942  Layer Size 26 beta 0.312894281036697\n",
      "Test loss window average  0.6264633  increasing, breaking loop at iter  1775\n",
      "Best number of iterations:  1775 compared with total: 71133\n",
      "old loss: 0.63470554\n",
      "new loss: 0.625639021396637\n",
      "best model updated\n",
      "======== Trial 0 of 1 =========\n",
      "Batch size 40  Iters 73034  Lr 0.0023995541377707184  Layers 4  Dropout 0.3355527682709091  Layer Size 14 beta 0.5301978130540447\n",
      "Test loss window average  354.06665  increasing, breaking loop at iter  1265\n",
      "Best number of iterations:  1265 compared with total: 73034\n",
      "old loss: 10000000000.0\n",
      "new loss: 362.3492126464844\n",
      "best model updated\n",
      "======== Trial 1 of 1 =========\n",
      "Batch size 28  Iters 29184  Lr 0.004471220812959276  Layers 5  Dropout 0.14463408726859198  Layer Size 24 beta 0.8506369227100489\n",
      "Test loss window average  584.8518  increasing, breaking loop at iter  755\n",
      "Best number of iterations:  755 compared with total: 29184\n"
     ]
    }
   ],
   "source": [
    "# First establish ground truth treatment effect:\n",
    "N = 5000000\n",
    "Z, x, y, Y1, Y0 = generate_data(N, seed=0)\n",
    "true_psi = (Y1-Y0).mean()\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "# Set some params\n",
    "N = 10000\n",
    "seed = 0\n",
    "num_tuning_trials = 100\n",
    "\n",
    "# data generation:\n",
    "z, x, y, _, _ = generate_data(N, 0)\n",
    "x = torch.tensor(x).type(torch.float32)\n",
    "z = torch.tensor(z).type(torch.float32)\n",
    "y = torch.tensor(y).type(torch.float32)\n",
    "\n",
    "gtuner = Tuner(x=x,y=y,z=z, net_type='G', trials=num_tuning_trials)\n",
    "gtuning_history, best_g, x_pred, _ = gtuner.tune()\n",
    "\n",
    "gtotal_losses = np.asarray(gtuning_history['best_model_test_loss'])\n",
    "gbest_index = np.argmin(gtotal_losses)\n",
    "\n",
    "gbest_params = {}\n",
    "for key in gtuning_history.keys():\n",
    "    gbest_params[key] = gtuning_history[key][gbest_index]\n",
    "    \n",
    "    \n",
    "qtuner = Tuner(x=x,y=y,z=z, x_pred=x_pred, net_type='Q', trials=num_tuning_trials)\n",
    "qtuning_history, best_q, _, eps = qtuner.tune()\n",
    "\n",
    "qtotal_losses = np.asarray(qtuning_history['best_model_test_loss'])\n",
    "qbest_index = np.argmin(qtotal_losses)\n",
    "\n",
    "qbest_params = {}\n",
    "for key in qtuning_history.keys():\n",
    "    qbest_params[key] = qtuning_history[key][qbest_index]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475fa678",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4090404",
   "metadata": {},
   "source": [
    "## 6. Run Simulation\n",
    "\n",
    "Now we have the best hyperparameters, we will run the simulations accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9709b014",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Q params: {'batch_size': 15, 'layers': 2, 'dropout': 0.26173975978416825, 'beta': 0.0024682746132177226, 'layer_size': 25, 'lr': 0.0013802296761695153, 'iters': 34618, 'stop_it': 2030, 'train_loss': 1.589935541152954, 'val_loss': 2.155715227127075, 'best_model_test_loss': array(2.1579423, dtype=float32)}\n",
      "Best G params: {'batch_size': 30, 'layers': 3, 'dropout': 0.3271170998197793, 'beta': 0.3810652928977, 'layer_size': 28, 'lr': 0.009084546077540867, 'iters': 23395, 'stop_it': 1010, 'train_loss': 0.5902615189552307, 'val_loss': 0.5865017771720886, 'best_model_test_loss': array(0.5796729, dtype=float32)}\n",
      "=====================RUN 0===================\n",
      "Test loss window average  0.6051667  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.54918075  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.2943072  increasing, breaking loop at iter  500\n",
      "=====================RUN 1===================\n",
      "Test loss window average  0.61398077  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.5555682  increasing, breaking loop at iter  2285\n",
      "Test loss window average  2.1687145  increasing, breaking loop at iter  1010\n",
      "=====================RUN 2===================\n",
      "Test loss window average  0.59405935  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.5410557  increasing, breaking loop at iter  755\n",
      "Test loss window average  2.2428243  increasing, breaking loop at iter  1010\n",
      "=====================RUN 3===================\n",
      "Test loss window average  0.61208636  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.5550837  increasing, breaking loop at iter  2030\n",
      "Test loss window average  2.1773362  increasing, breaking loop at iter  500\n",
      "=====================RUN 4===================\n",
      "Test loss window average  0.60096353  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.5465918  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.143866  increasing, breaking loop at iter  500\n",
      "=====================RUN 5===================\n",
      "Test loss window average  0.61243266  increasing, breaking loop at iter  500\n",
      "Test loss window average  0.5152413  increasing, breaking loop at iter  2285\n",
      "Test loss window average  2.1910162  increasing, breaking loop at iter  500\n",
      "=====================RUN 6===================\n",
      "Test loss window average  0.6182298  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.5557494  increasing, breaking loop at iter  1775\n",
      "Test loss window average  2.3264055  increasing, breaking loop at iter  1265\n",
      "=====================RUN 7===================\n",
      "Test loss window average  0.6010267  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.5437495  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.1503413  increasing, breaking loop at iter  755\n",
      "=====================RUN 8===================\n",
      "Test loss window average  0.61094403  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.5624791  increasing, breaking loop at iter  755\n",
      "Test loss window average  2.275211  increasing, breaking loop at iter  1265\n",
      "=====================RUN 9===================\n",
      "Test loss window average  0.60363775  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.5374912  increasing, breaking loop at iter  2540\n",
      "Test loss window average  2.2732286  increasing, breaking loop at iter  1010\n",
      "=====================RUN 10===================\n",
      "Test loss window average  0.6195799  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.5613051  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.2076263  increasing, breaking loop at iter  1775\n",
      "=====================RUN 11===================\n",
      "Test loss window average  0.5983525  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.5404605  increasing, breaking loop at iter  755\n",
      "Test loss window average  2.179651  increasing, breaking loop at iter  1265\n",
      "=====================RUN 12===================\n",
      "Test loss window average  0.6141403  increasing, breaking loop at iter  2030\n",
      "Test loss window average  0.53699183  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.1852646  increasing, breaking loop at iter  2030\n",
      "=====================RUN 13===================\n",
      "Test loss window average  0.59695125  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.534509  increasing, breaking loop at iter  3305\n",
      "Test loss window average  2.129892  increasing, breaking loop at iter  1010\n",
      "=====================RUN 14===================\n",
      "Test loss window average  0.6093928  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.55683553  increasing, breaking loop at iter  2540\n",
      "Test loss window average  2.1845264  increasing, breaking loop at iter  500\n",
      "=====================RUN 15===================\n",
      "Test loss window average  0.6124902  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.5493385  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.1858094  increasing, breaking loop at iter  500\n",
      "=====================RUN 16===================\n",
      "Test loss window average  0.6222703  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.5469508  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.2040904  increasing, breaking loop at iter  755\n",
      "=====================RUN 17===================\n",
      "Test loss window average  0.6176483  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.55439097  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.1963599  increasing, breaking loop at iter  755\n",
      "=====================RUN 18===================\n",
      "Test loss window average  0.6199634  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.53680134  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.1905532  increasing, breaking loop at iter  500\n",
      "=====================RUN 19===================\n",
      "Test loss window average  0.62450767  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.5557166  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.2410579  increasing, breaking loop at iter  500\n",
      "=====================RUN 20===================\n",
      "Test loss window average  0.6177166  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.5381502  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.0656316  increasing, breaking loop at iter  755\n",
      "=====================RUN 21===================\n",
      "Test loss window average  0.6159692  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.54302734  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.2147062  increasing, breaking loop at iter  500\n",
      "=====================RUN 22===================\n",
      "Test loss window average  0.60915166  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.5391907  increasing, breaking loop at iter  3560\n",
      "Test loss window average  2.2078512  increasing, breaking loop at iter  755\n",
      "=====================RUN 23===================\n",
      "Test loss window average  0.6015032  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.55414695  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.255094  increasing, breaking loop at iter  755\n",
      "=====================RUN 24===================\n",
      "Test loss window average  0.60196537  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.5284446  increasing, breaking loop at iter  2030\n",
      "Test loss window average  2.1879466  increasing, breaking loop at iter  1010\n",
      "=====================RUN 25===================\n",
      "Test loss window average  0.6079599  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.56125313  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.2160711  increasing, breaking loop at iter  1775\n",
      "=====================RUN 26===================\n",
      "Test loss window average  0.6007759  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.53656507  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.1901138  increasing, breaking loop at iter  755\n",
      "=====================RUN 27===================\n",
      "Test loss window average  0.61716545  increasing, breaking loop at iter  3050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss window average  0.5239241  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.258516  increasing, breaking loop at iter  500\n",
      "=====================RUN 28===================\n",
      "Test loss window average  0.5879928  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.53634244  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.2452106  increasing, breaking loop at iter  500\n",
      "=====================RUN 29===================\n",
      "Test loss window average  0.6079159  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.53197503  increasing, breaking loop at iter  755\n",
      "Test loss window average  2.2638884  increasing, breaking loop at iter  1010\n",
      "=====================RUN 30===================\n",
      "Test loss window average  0.6068845  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.5682633  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.248047  increasing, breaking loop at iter  500\n",
      "=====================RUN 31===================\n",
      "Test loss window average  0.625718  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.54222715  increasing, breaking loop at iter  2030\n",
      "Test loss window average  2.2482722  increasing, breaking loop at iter  2030\n",
      "=====================RUN 32===================\n",
      "Test loss window average  0.5945489  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.52498776  increasing, breaking loop at iter  3305\n",
      "Test loss window average  2.2567132  increasing, breaking loop at iter  500\n",
      "=====================RUN 33===================\n",
      "Test loss window average  0.63208175  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.5504095  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.220537  increasing, breaking loop at iter  1265\n",
      "=====================RUN 34===================\n",
      "Test loss window average  0.6102847  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.53184587  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.1559992  increasing, breaking loop at iter  1010\n",
      "=====================RUN 35===================\n",
      "Test loss window average  0.61616933  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.5660338  increasing, breaking loop at iter  755\n",
      "Test loss window average  2.3111253  increasing, breaking loop at iter  1520\n",
      "=====================RUN 36===================\n",
      "Test loss window average  0.6080883  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.5407534  increasing, breaking loop at iter  3050\n",
      "Test loss window average  2.1861608  increasing, breaking loop at iter  755\n",
      "=====================RUN 37===================\n",
      "Test loss window average  0.63751036  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.5495218  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.286411  increasing, breaking loop at iter  755\n",
      "=====================RUN 38===================\n",
      "Test loss window average  0.6115993  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.55415416  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.2581675  increasing, breaking loop at iter  1520\n",
      "=====================RUN 39===================\n",
      "Test loss window average  0.6101172  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.5329212  increasing, breaking loop at iter  1775\n",
      "Test loss window average  2.1024232  increasing, breaking loop at iter  500\n",
      "=====================RUN 40===================\n",
      "Test loss window average  0.6142332  increasing, breaking loop at iter  2540\n",
      "Test loss window average  0.54919815  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.2619104  increasing, breaking loop at iter  1265\n",
      "=====================RUN 41===================\n",
      "Test loss window average  0.6054732  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.52200776  increasing, breaking loop at iter  2285\n",
      "Test loss window average  2.263697  increasing, breaking loop at iter  1010\n",
      "=====================RUN 42===================\n",
      "Test loss window average  0.60562766  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.56525224  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.254053  increasing, breaking loop at iter  1010\n",
      "=====================RUN 43===================\n",
      "Test loss window average  0.61421645  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.53161234  increasing, breaking loop at iter  2285\n",
      "Test loss window average  2.0245516  increasing, breaking loop at iter  500\n",
      "=====================RUN 44===================\n",
      "Test loss window average  0.6027726  increasing, breaking loop at iter  2285\n",
      "Test loss window average  0.5387873  increasing, breaking loop at iter  3050\n",
      "Test loss window average  2.2442129  increasing, breaking loop at iter  500\n",
      "=====================RUN 45===================\n",
      "Test loss window average  0.6054745  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.52043515  increasing, breaking loop at iter  2540\n",
      "Test loss window average  2.1164503  increasing, breaking loop at iter  500\n",
      "=====================RUN 46===================\n",
      "Test loss window average  0.6083173  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.5515947  increasing, breaking loop at iter  2795\n",
      "Test loss window average  2.160138  increasing, breaking loop at iter  755\n",
      "=====================RUN 47===================\n",
      "Test loss window average  0.61778986  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.54524064  increasing, breaking loop at iter  2795\n",
      "Test loss window average  2.218809  increasing, breaking loop at iter  1010\n",
      "=====================RUN 48===================\n",
      "Test loss window average  0.5942919  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.55149055  increasing, breaking loop at iter  2285\n",
      "Test loss window average  2.1670816  increasing, breaking loop at iter  755\n",
      "=====================RUN 49===================\n",
      "Test loss window average  0.60447454  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.5480151  increasing, breaking loop at iter  3050\n",
      "Test loss window average  2.157995  increasing, breaking loop at iter  500\n",
      "=====================RUN 50===================\n",
      "Test loss window average  0.6072112  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.52631986  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.18258  increasing, breaking loop at iter  755\n",
      "=====================RUN 51===================\n",
      "Test loss window average  0.6033183  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.5286993  increasing, breaking loop at iter  2540\n",
      "Test loss window average  2.138943  increasing, breaking loop at iter  2030\n",
      "=====================RUN 52===================\n",
      "Test loss window average  0.6259885  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.55872256  increasing, breaking loop at iter  3815\n",
      "Test loss window average  2.2650373  increasing, breaking loop at iter  500\n",
      "=====================RUN 53===================\n",
      "Test loss window average  0.6071807  increasing, breaking loop at iter  2030\n",
      "Test loss window average  0.51705164  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.1880567  increasing, breaking loop at iter  1265\n",
      "=====================RUN 54===================\n",
      "Test loss window average  0.6100808  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.5489632  increasing, breaking loop at iter  755\n",
      "Test loss window average  2.218418  increasing, breaking loop at iter  1010\n",
      "=====================RUN 55===================\n",
      "Test loss window average  0.6114443  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.53480077  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.2053018  increasing, breaking loop at iter  1775\n",
      "=====================RUN 56===================\n",
      "Test loss window average  0.6120071  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.5726713  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.2573435  increasing, breaking loop at iter  1775\n",
      "=====================RUN 57===================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss window average  0.6156538  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.5493129  increasing, breaking loop at iter  2285\n",
      "Test loss window average  2.2717316  increasing, breaking loop at iter  755\n",
      "=====================RUN 58===================\n",
      "Test loss window average  0.6143686  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.522907  increasing, breaking loop at iter  755\n",
      "Test loss window average  2.2733796  increasing, breaking loop at iter  500\n",
      "=====================RUN 59===================\n",
      "Test loss window average  0.61040735  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.5531055  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.2316775  increasing, breaking loop at iter  500\n",
      "=====================RUN 60===================\n",
      "Test loss window average  0.59992373  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.556571  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.215167  increasing, breaking loop at iter  1265\n",
      "=====================RUN 61===================\n",
      "Test loss window average  0.5996721  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.51400054  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.1284115  increasing, breaking loop at iter  1265\n",
      "=====================RUN 62===================\n",
      "Test loss window average  0.60539186  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.52780974  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.156305  increasing, breaking loop at iter  500\n",
      "=====================RUN 63===================\n",
      "Test loss window average  0.6095553  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.5151643  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.064799  increasing, breaking loop at iter  500\n",
      "=====================RUN 64===================\n",
      "Test loss window average  0.61209595  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.5258035  increasing, breaking loop at iter  4580\n",
      "Test loss window average  2.1707482  increasing, breaking loop at iter  755\n",
      "=====================RUN 65===================\n",
      "Test loss window average  0.6129631  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.53360355  increasing, breaking loop at iter  1775\n",
      "Test loss window average  2.1366975  increasing, breaking loop at iter  755\n",
      "=====================RUN 66===================\n",
      "Test loss window average  0.6088105  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.5397275  increasing, breaking loop at iter  2285\n",
      "Test loss window average  2.151616  increasing, breaking loop at iter  755\n",
      "=====================RUN 67===================\n",
      "Test loss window average  0.6127231  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.54183286  increasing, breaking loop at iter  2285\n",
      "Test loss window average  2.1487103  increasing, breaking loop at iter  500\n",
      "=====================RUN 68===================\n",
      "Test loss window average  0.62066627  increasing, breaking loop at iter  2540\n",
      "Test loss window average  0.54356617  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.1982956  increasing, breaking loop at iter  500\n",
      "=====================RUN 69===================\n",
      "Test loss window average  0.5927791  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.54699004  increasing, breaking loop at iter  2540\n",
      "Test loss window average  2.234682  increasing, breaking loop at iter  500\n",
      "=====================RUN 70===================\n",
      "Test loss window average  0.60701764  increasing, breaking loop at iter  2030\n",
      "Test loss window average  0.5547728  increasing, breaking loop at iter  1775\n",
      "Test loss window average  2.2329013  increasing, breaking loop at iter  500\n",
      "=====================RUN 71===================\n",
      "Test loss window average  0.61305743  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.5440498  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.225843  increasing, breaking loop at iter  1265\n",
      "=====================RUN 72===================\n",
      "Test loss window average  0.6067471  increasing, breaking loop at iter  2030\n",
      "Test loss window average  0.5540308  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.2654796  increasing, breaking loop at iter  500\n",
      "=====================RUN 73===================\n",
      "Test loss window average  0.6155924  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.543571  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.2353115  increasing, breaking loop at iter  1775\n",
      "=====================RUN 74===================\n",
      "Test loss window average  0.6096533  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.53732073  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.3692913  increasing, breaking loop at iter  500\n",
      "=====================RUN 75===================\n",
      "Test loss window average  0.616147  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.54717886  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.3020372  increasing, breaking loop at iter  1010\n",
      "=====================RUN 76===================\n",
      "Test loss window average  0.60322404  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.5324376  increasing, breaking loop at iter  1775\n",
      "Test loss window average  2.167339  increasing, breaking loop at iter  755\n",
      "=====================RUN 77===================\n",
      "Test loss window average  0.6085184  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.5368752  increasing, breaking loop at iter  2285\n",
      "Test loss window average  2.1599953  increasing, breaking loop at iter  755\n",
      "=====================RUN 78===================\n",
      "Test loss window average  0.61938787  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.54034203  increasing, breaking loop at iter  2030\n",
      "Test loss window average  2.226633  increasing, breaking loop at iter  1265\n",
      "=====================RUN 79===================\n",
      "Test loss window average  0.6174159  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.53628457  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.2630048  increasing, breaking loop at iter  500\n",
      "=====================RUN 80===================\n",
      "Test loss window average  0.61488706  increasing, breaking loop at iter  2795\n",
      "Test loss window average  0.54986185  increasing, breaking loop at iter  3560\n",
      "Test loss window average  2.212149  increasing, breaking loop at iter  1265\n",
      "=====================RUN 81===================\n",
      "Test loss window average  0.62844926  increasing, breaking loop at iter  500\n",
      "Test loss window average  0.5344943  increasing, breaking loop at iter  3305\n",
      "Test loss window average  2.2242177  increasing, breaking loop at iter  1520\n",
      "=====================RUN 82===================\n",
      "Test loss window average  0.6026327  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.54251504  increasing, breaking loop at iter  2540\n",
      "Test loss window average  2.1784968  increasing, breaking loop at iter  1010\n",
      "=====================RUN 83===================\n",
      "Test loss window average  0.6090509  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.5409847  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.1645522  increasing, breaking loop at iter  1010\n",
      "=====================RUN 84===================\n",
      "Test loss window average  0.61937886  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.53716505  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.1961548  increasing, breaking loop at iter  500\n",
      "=====================RUN 85===================\n",
      "Test loss window average  0.6068689  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.5648445  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.1966238  increasing, breaking loop at iter  1520\n",
      "=====================RUN 86===================\n",
      "Test loss window average  0.6198615  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.5431425  increasing, breaking loop at iter  2795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss window average  2.2170484  increasing, breaking loop at iter  500\n",
      "=====================RUN 87===================\n",
      "Test loss window average  0.6036553  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.5452759  increasing, breaking loop at iter  1775\n",
      "Test loss window average  2.2428808  increasing, breaking loop at iter  1775\n",
      "=====================RUN 88===================\n",
      "Test loss window average  0.6063592  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.55502343  increasing, breaking loop at iter  3050\n",
      "Test loss window average  2.189733  increasing, breaking loop at iter  500\n",
      "=====================RUN 89===================\n",
      "Test loss window average  0.62284607  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.5330737  increasing, breaking loop at iter  755\n",
      "Test loss window average  2.22586  increasing, breaking loop at iter  1520\n",
      "=====================RUN 90===================\n",
      "Test loss window average  0.617473  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.54199356  increasing, breaking loop at iter  1775\n",
      "Test loss window average  2.1740046  increasing, breaking loop at iter  1010\n",
      "=====================RUN 91===================\n",
      "Test loss window average  0.61524755  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.53645223  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.2441773  increasing, breaking loop at iter  755\n",
      "=====================RUN 92===================\n",
      "Test loss window average  0.60286087  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.5401301  increasing, breaking loop at iter  2795\n",
      "Test loss window average  2.258318  increasing, breaking loop at iter  2285\n",
      "=====================RUN 93===================\n",
      "Test loss window average  0.612825  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.58586276  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.2335317  increasing, breaking loop at iter  1520\n",
      "=====================RUN 94===================\n",
      "Test loss window average  0.60630316  increasing, breaking loop at iter  2030\n",
      "Test loss window average  0.5463926  increasing, breaking loop at iter  2795\n",
      "Test loss window average  2.2214096  increasing, breaking loop at iter  1010\n",
      "=====================RUN 95===================\n",
      "Test loss window average  0.60737973  increasing, breaking loop at iter  2030\n",
      "Test loss window average  0.54705656  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.258799  increasing, breaking loop at iter  500\n",
      "=====================RUN 96===================\n",
      "Test loss window average  0.6111151  increasing, breaking loop at iter  2030\n",
      "Test loss window average  0.55522895  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.202904  increasing, breaking loop at iter  755\n",
      "=====================RUN 97===================\n",
      "Test loss window average  0.6002063  increasing, breaking loop at iter  2030\n",
      "Test loss window average  0.5270512  increasing, breaking loop at iter  1775\n",
      "Test loss window average  2.2590108  increasing, breaking loop at iter  2030\n",
      "=====================RUN 98===================\n",
      "Test loss window average  0.5984385  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.54917055  increasing, breaking loop at iter  4835\n",
      "Test loss window average  2.1787202  increasing, breaking loop at iter  500\n",
      "=====================RUN 99===================\n",
      "Test loss window average  0.61027443  increasing, breaking loop at iter  2030\n",
      "Test loss window average  0.54820466  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.2332823  increasing, breaking loop at iter  500\n",
      "=====================RUN 100===================\n",
      "Test loss window average  0.6213874  increasing, breaking loop at iter  2030\n",
      "Test loss window average  0.55073285  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.1378524  increasing, breaking loop at iter  1775\n",
      "=====================RUN 101===================\n",
      "Test loss window average  0.6319191  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.54763246  increasing, breaking loop at iter  3305\n",
      "Test loss window average  2.1489897  increasing, breaking loop at iter  500\n",
      "=====================RUN 102===================\n",
      "Test loss window average  0.62595844  increasing, breaking loop at iter  2030\n",
      "Test loss window average  0.5167463  increasing, breaking loop at iter  1775\n",
      "Test loss window average  2.1840394  increasing, breaking loop at iter  1265\n",
      "=====================RUN 103===================\n",
      "Test loss window average  0.6243997  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.5372206  increasing, breaking loop at iter  2540\n",
      "Test loss window average  2.2304466  increasing, breaking loop at iter  1010\n",
      "=====================RUN 104===================\n",
      "Test loss window average  0.599539  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.5443035  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.0969777  increasing, breaking loop at iter  1010\n",
      "=====================RUN 105===================\n",
      "Test loss window average  0.6166215  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.52743936  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.172597  increasing, breaking loop at iter  1265\n",
      "=====================RUN 106===================\n",
      "Test loss window average  0.60757506  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.519974  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.268625  increasing, breaking loop at iter  500\n",
      "=====================RUN 107===================\n",
      "Test loss window average  0.60266006  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.55947524  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.1751733  increasing, breaking loop at iter  755\n",
      "=====================RUN 108===================\n",
      "Test loss window average  0.59738004  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.52435076  increasing, breaking loop at iter  2030\n",
      "Test loss window average  2.1544983  increasing, breaking loop at iter  500\n",
      "=====================RUN 109===================\n",
      "Test loss window average  0.6050322  increasing, breaking loop at iter  500\n",
      "Test loss window average  0.5404531  increasing, breaking loop at iter  3815\n",
      "Test loss window average  2.173789  increasing, breaking loop at iter  500\n",
      "=====================RUN 110===================\n",
      "Test loss window average  0.59428364  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.5530293  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.2472167  increasing, breaking loop at iter  1520\n",
      "=====================RUN 111===================\n",
      "Test loss window average  0.58811754  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.53641355  increasing, breaking loop at iter  3305\n",
      "Test loss window average  2.2330847  increasing, breaking loop at iter  500\n",
      "=====================RUN 112===================\n",
      "Test loss window average  0.61604047  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.5388887  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.21937  increasing, breaking loop at iter  1265\n",
      "=====================RUN 113===================\n",
      "Test loss window average  0.5994071  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.53674036  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.1718261  increasing, breaking loop at iter  1010\n",
      "=====================RUN 114===================\n",
      "Test loss window average  0.6189286  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.55726594  increasing, breaking loop at iter  3050\n",
      "Test loss window average  2.1961586  increasing, breaking loop at iter  500\n",
      "=====================RUN 115===================\n",
      "Test loss window average  0.6112011  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.54817325  increasing, breaking loop at iter  2030\n",
      "Test loss window average  2.2549818  increasing, breaking loop at iter  500\n",
      "=====================RUN 116===================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss window average  0.6152781  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.5241183  increasing, breaking loop at iter  2030\n",
      "Test loss window average  2.1303794  increasing, breaking loop at iter  755\n",
      "=====================RUN 117===================\n",
      "Test loss window average  0.6209866  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.5632925  increasing, breaking loop at iter  1775\n",
      "Test loss window average  2.189472  increasing, breaking loop at iter  1010\n",
      "=====================RUN 118===================\n",
      "Test loss window average  0.58972853  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.5415104  increasing, breaking loop at iter  755\n",
      "Test loss window average  2.1625566  increasing, breaking loop at iter  1265\n",
      "=====================RUN 119===================\n",
      "Test loss window average  0.6267154  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.5246642  increasing, breaking loop at iter  2285\n",
      "Test loss window average  2.2340212  increasing, breaking loop at iter  1265\n",
      "=====================RUN 120===================\n",
      "Test loss window average  0.601739  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.54211825  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.3144724  increasing, breaking loop at iter  755\n",
      "=====================RUN 121===================\n",
      "Test loss window average  0.6167703  increasing, breaking loop at iter  2030\n",
      "Test loss window average  0.572934  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.2468266  increasing, breaking loop at iter  500\n",
      "=====================RUN 122===================\n",
      "Test loss window average  0.6258172  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.547669  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.1750016  increasing, breaking loop at iter  1010\n",
      "=====================RUN 123===================\n",
      "Test loss window average  0.5967979  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.52697927  increasing, breaking loop at iter  2030\n",
      "Test loss window average  2.2089515  increasing, breaking loop at iter  1775\n",
      "=====================RUN 124===================\n",
      "Test loss window average  0.6176002  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.54859674  increasing, breaking loop at iter  3560\n",
      "Test loss window average  2.2030458  increasing, breaking loop at iter  2285\n",
      "=====================RUN 125===================\n",
      "Test loss window average  0.60726964  increasing, breaking loop at iter  500\n",
      "Test loss window average  0.5430545  increasing, breaking loop at iter  755\n",
      "Test loss window average  2.2285163  increasing, breaking loop at iter  1265\n",
      "=====================RUN 126===================\n",
      "Test loss window average  0.6214787  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.5432237  increasing, breaking loop at iter  3815\n",
      "Test loss window average  2.282285  increasing, breaking loop at iter  755\n",
      "=====================RUN 127===================\n",
      "Test loss window average  0.60313284  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.55441463  increasing, breaking loop at iter  3815\n",
      "Test loss window average  2.234579  increasing, breaking loop at iter  500\n",
      "=====================RUN 128===================\n",
      "Test loss window average  0.61582243  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.53549856  increasing, breaking loop at iter  755\n",
      "Test loss window average  2.3078887  increasing, breaking loop at iter  1010\n",
      "=====================RUN 129===================\n",
      "Test loss window average  0.61467874  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.54130054  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.2685223  increasing, breaking loop at iter  3815\n",
      "=====================RUN 130===================\n",
      "Test loss window average  0.6233594  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.5559399  increasing, breaking loop at iter  755\n",
      "Test loss window average  2.3073368  increasing, breaking loop at iter  1010\n",
      "=====================RUN 131===================\n",
      "Test loss window average  0.6070977  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.5298065  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.2183552  increasing, breaking loop at iter  1010\n",
      "=====================RUN 132===================\n",
      "Test loss window average  0.5862295  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.538203  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.318026  increasing, breaking loop at iter  500\n",
      "=====================RUN 133===================\n",
      "Test loss window average  0.6046507  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.54363877  increasing, breaking loop at iter  3305\n",
      "Test loss window average  2.2747743  increasing, breaking loop at iter  500\n",
      "=====================RUN 134===================\n",
      "Test loss window average  0.59884304  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.5712591  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.1891413  increasing, breaking loop at iter  755\n",
      "=====================RUN 135===================\n",
      "Test loss window average  0.611253  increasing, breaking loop at iter  500\n",
      "Test loss window average  0.5246659  increasing, breaking loop at iter  2795\n",
      "Test loss window average  2.167298  increasing, breaking loop at iter  1520\n",
      "=====================RUN 136===================\n",
      "Test loss window average  0.6068214  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.55296206  increasing, breaking loop at iter  2285\n",
      "Test loss window average  2.1228313  increasing, breaking loop at iter  500\n",
      "=====================RUN 137===================\n",
      "Test loss window average  0.60422385  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.523708  increasing, breaking loop at iter  1775\n",
      "Test loss window average  2.1688788  increasing, breaking loop at iter  1265\n",
      "=====================RUN 138===================\n",
      "Test loss window average  0.6119398  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.5353703  increasing, breaking loop at iter  3305\n",
      "Test loss window average  2.2149765  increasing, breaking loop at iter  1265\n",
      "=====================RUN 139===================\n",
      "Test loss window average  0.60135967  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.5383265  increasing, breaking loop at iter  2030\n",
      "Test loss window average  2.193658  increasing, breaking loop at iter  500\n",
      "=====================RUN 140===================\n",
      "Test loss window average  0.61675  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.5467105  increasing, breaking loop at iter  2285\n",
      "Test loss window average  2.2211382  increasing, breaking loop at iter  1010\n",
      "=====================RUN 141===================\n",
      "Test loss window average  0.60463184  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.5218511  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.1720917  increasing, breaking loop at iter  755\n",
      "=====================RUN 142===================\n",
      "Test loss window average  0.6264306  increasing, breaking loop at iter  2030\n",
      "Test loss window average  0.54138875  increasing, breaking loop at iter  3305\n",
      "Test loss window average  2.1271834  increasing, breaking loop at iter  500\n",
      "=====================RUN 143===================\n",
      "Test loss window average  0.6178549  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.56279105  increasing, breaking loop at iter  755\n",
      "Test loss window average  2.1796074  increasing, breaking loop at iter  1010\n",
      "=====================RUN 144===================\n",
      "Test loss window average  0.60956305  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.5044467  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.2002373  increasing, breaking loop at iter  1265\n",
      "=====================RUN 145===================\n",
      "Test loss window average  0.6159302  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.5421538  increasing, breaking loop at iter  1520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss window average  2.2209275  increasing, breaking loop at iter  500\n",
      "=====================RUN 146===================\n",
      "Test loss window average  0.6096224  increasing, breaking loop at iter  2285\n",
      "Test loss window average  0.5585019  increasing, breaking loop at iter  2540\n",
      "Test loss window average  2.140497  increasing, breaking loop at iter  500\n",
      "=====================RUN 147===================\n",
      "Test loss window average  0.585158  increasing, breaking loop at iter  2030\n",
      "Test loss window average  0.55043584  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.2020104  increasing, breaking loop at iter  755\n",
      "=====================RUN 148===================\n",
      "Test loss window average  0.6019926  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.5463021  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.1850846  increasing, breaking loop at iter  1265\n",
      "=====================RUN 149===================\n",
      "Test loss window average  0.6216552  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.5395483  increasing, breaking loop at iter  4070\n",
      "Test loss window average  2.1817608  increasing, breaking loop at iter  500\n",
      "=====================RUN 150===================\n",
      "Test loss window average  0.6136154  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.5624499  increasing, breaking loop at iter  2285\n",
      "Test loss window average  2.2611303  increasing, breaking loop at iter  755\n",
      "=====================RUN 151===================\n",
      "Test loss window average  0.6180237  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.553573  increasing, breaking loop at iter  2030\n",
      "Test loss window average  2.2941117  increasing, breaking loop at iter  500\n",
      "=====================RUN 152===================\n",
      "Test loss window average  0.61243063  increasing, breaking loop at iter  2285\n",
      "Test loss window average  0.54412085  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.2074137  increasing, breaking loop at iter  500\n",
      "=====================RUN 153===================\n",
      "Test loss window average  0.6051728  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.5316806  increasing, breaking loop at iter  2285\n",
      "Test loss window average  2.2354884  increasing, breaking loop at iter  2030\n",
      "=====================RUN 154===================\n",
      "Test loss window average  0.61194575  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.5341542  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.1363666  increasing, breaking loop at iter  755\n",
      "=====================RUN 155===================\n",
      "Test loss window average  0.6097968  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.5352449  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.194097  increasing, breaking loop at iter  500\n",
      "=====================RUN 156===================\n",
      "Test loss window average  0.599115  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.56189454  increasing, breaking loop at iter  2030\n",
      "Test loss window average  2.126924  increasing, breaking loop at iter  1010\n",
      "=====================RUN 157===================\n",
      "Test loss window average  0.61385065  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.55265677  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.209389  increasing, breaking loop at iter  1010\n",
      "=====================RUN 158===================\n",
      "Test loss window average  0.6151045  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.569432  increasing, breaking loop at iter  3815\n",
      "Test loss window average  2.2482264  increasing, breaking loop at iter  500\n",
      "=====================RUN 159===================\n",
      "Test loss window average  0.58763456  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.5420306  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.179108  increasing, breaking loop at iter  755\n",
      "=====================RUN 160===================\n",
      "Test loss window average  0.6125663  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.54569393  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.1429465  increasing, breaking loop at iter  755\n",
      "=====================RUN 161===================\n",
      "Test loss window average  0.60599744  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.5364356  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.206268  increasing, breaking loop at iter  500\n",
      "=====================RUN 162===================\n",
      "Test loss window average  0.6098678  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.5370514  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.232121  increasing, breaking loop at iter  2285\n",
      "=====================RUN 163===================\n",
      "Test loss window average  0.59568053  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.5558972  increasing, breaking loop at iter  1775\n",
      "Test loss window average  2.155604  increasing, breaking loop at iter  755\n",
      "=====================RUN 164===================\n",
      "Test loss window average  0.60142976  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.56832784  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.1221159  increasing, breaking loop at iter  755\n",
      "=====================RUN 165===================\n",
      "Test loss window average  0.60030085  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.5489981  increasing, breaking loop at iter  2795\n",
      "Test loss window average  2.2497914  increasing, breaking loop at iter  755\n",
      "=====================RUN 166===================\n",
      "Test loss window average  0.60831  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.5126537  increasing, breaking loop at iter  1775\n",
      "Test loss window average  2.1742263  increasing, breaking loop at iter  755\n",
      "=====================RUN 167===================\n",
      "Test loss window average  0.6195615  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.54943234  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.2441657  increasing, breaking loop at iter  1265\n",
      "=====================RUN 168===================\n",
      "Test loss window average  0.60633045  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.54875326  increasing, breaking loop at iter  2030\n",
      "Test loss window average  2.3026872  increasing, breaking loop at iter  500\n",
      "=====================RUN 169===================\n",
      "Test loss window average  0.6067409  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.54028845  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.221456  increasing, breaking loop at iter  2540\n",
      "=====================RUN 170===================\n",
      "Test loss window average  0.6056261  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.5355591  increasing, breaking loop at iter  2285\n",
      "Test loss window average  2.1139677  increasing, breaking loop at iter  1265\n",
      "=====================RUN 171===================\n",
      "Test loss window average  0.60037506  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.55757993  increasing, breaking loop at iter  755\n",
      "Test loss window average  2.161678  increasing, breaking loop at iter  755\n",
      "=====================RUN 172===================\n",
      "Test loss window average  0.60920274  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.5548396  increasing, breaking loop at iter  755\n",
      "Test loss window average  2.2002478  increasing, breaking loop at iter  2285\n",
      "=====================RUN 173===================\n",
      "Test loss window average  0.61453295  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.5623569  increasing, breaking loop at iter  755\n",
      "Test loss window average  2.2513022  increasing, breaking loop at iter  1265\n",
      "=====================RUN 174===================\n",
      "Test loss window average  0.61401254  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.5303746  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.1616697  increasing, breaking loop at iter  500\n",
      "=====================RUN 175===================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss window average  0.62530524  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.563978  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.1839154  increasing, breaking loop at iter  500\n",
      "=====================RUN 176===================\n",
      "Test loss window average  0.60962075  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.5367886  increasing, breaking loop at iter  1775\n",
      "Test loss window average  2.220149  increasing, breaking loop at iter  755\n",
      "=====================RUN 177===================\n",
      "Test loss window average  0.6195863  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.55764365  increasing, breaking loop at iter  1775\n",
      "Test loss window average  2.1957555  increasing, breaking loop at iter  755\n",
      "=====================RUN 178===================\n",
      "Test loss window average  0.60016906  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.5639135  increasing, breaking loop at iter  755\n",
      "Test loss window average  2.176739  increasing, breaking loop at iter  1265\n",
      "=====================RUN 179===================\n",
      "Test loss window average  0.6105909  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.5553237  increasing, breaking loop at iter  4070\n",
      "Test loss window average  2.2778754  increasing, breaking loop at iter  1010\n",
      "=====================RUN 180===================\n",
      "Test loss window average  0.61736286  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.5454122  increasing, breaking loop at iter  2540\n",
      "Test loss window average  2.1811242  increasing, breaking loop at iter  500\n",
      "=====================RUN 181===================\n",
      "Test loss window average  0.6133196  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.5364052  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.2645054  increasing, breaking loop at iter  1265\n",
      "=====================RUN 182===================\n",
      "Test loss window average  0.62603676  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.5362263  increasing, breaking loop at iter  3305\n",
      "Test loss window average  2.2421806  increasing, breaking loop at iter  1010\n",
      "=====================RUN 183===================\n",
      "Test loss window average  0.6197993  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.5638695  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.151921  increasing, breaking loop at iter  500\n",
      "=====================RUN 184===================\n",
      "Test loss window average  0.6110104  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.56373614  increasing, breaking loop at iter  3305\n",
      "Test loss window average  2.2736619  increasing, breaking loop at iter  500\n",
      "=====================RUN 185===================\n",
      "Test loss window average  0.62968045  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.550767  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.2927692  increasing, breaking loop at iter  500\n",
      "=====================RUN 186===================\n",
      "Test loss window average  0.62313485  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.54193765  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.2795317  increasing, breaking loop at iter  3305\n",
      "=====================RUN 187===================\n",
      "Test loss window average  0.600941  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.56436956  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.2079935  increasing, breaking loop at iter  500\n",
      "=====================RUN 188===================\n",
      "Test loss window average  0.61822116  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.5305074  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.1620708  increasing, breaking loop at iter  1775\n",
      "=====================RUN 189===================\n",
      "Test loss window average  0.6183059  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.54093003  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.2407303  increasing, breaking loop at iter  755\n",
      "=====================RUN 190===================\n",
      "Test loss window average  0.6146779  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.55124444  increasing, breaking loop at iter  2540\n",
      "Test loss window average  2.1984391  increasing, breaking loop at iter  1010\n",
      "=====================RUN 191===================\n",
      "Test loss window average  0.6076668  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.5372399  increasing, breaking loop at iter  2795\n",
      "Test loss window average  2.2072523  increasing, breaking loop at iter  1265\n",
      "=====================RUN 192===================\n",
      "Test loss window average  0.58801496  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.5520792  increasing, breaking loop at iter  755\n",
      "Test loss window average  2.1905982  increasing, breaking loop at iter  1520\n",
      "=====================RUN 193===================\n",
      "Test loss window average  0.6323254  increasing, breaking loop at iter  2285\n",
      "Test loss window average  0.5450993  increasing, breaking loop at iter  3050\n",
      "Test loss window average  2.1971889  increasing, breaking loop at iter  755\n",
      "=====================RUN 194===================\n",
      "Test loss window average  0.6057371  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.53150874  increasing, breaking loop at iter  1775\n",
      "Test loss window average  2.1512306  increasing, breaking loop at iter  755\n",
      "=====================RUN 195===================\n",
      "Test loss window average  0.59513044  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.54238486  increasing, breaking loop at iter  2540\n",
      "Test loss window average  2.2131062  increasing, breaking loop at iter  1010\n",
      "=====================RUN 196===================\n",
      "Test loss window average  0.6016171  increasing, breaking loop at iter  2285\n",
      "Test loss window average  0.5317181  increasing, breaking loop at iter  755\n",
      "Test loss window average  2.190658  increasing, breaking loop at iter  500\n",
      "=====================RUN 197===================\n",
      "Test loss window average  0.6055897  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.55129355  increasing, breaking loop at iter  3305\n",
      "Test loss window average  2.233942  increasing, breaking loop at iter  500\n",
      "=====================RUN 198===================\n",
      "Test loss window average  0.5999006  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.5460019  increasing, breaking loop at iter  755\n",
      "Test loss window average  2.2060757  increasing, breaking loop at iter  500\n",
      "=====================RUN 199===================\n",
      "Test loss window average  0.61284703  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.54588425  increasing, breaking loop at iter  2795\n",
      "Test loss window average  2.2447627  increasing, breaking loop at iter  755\n",
      "=====================RUN 200===================\n",
      "Test loss window average  0.6150268  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.562768  increasing, breaking loop at iter  755\n",
      "Test loss window average  2.2019944  increasing, breaking loop at iter  755\n",
      "=====================RUN 201===================\n",
      "Test loss window average  0.61439204  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.5314412  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.2600155  increasing, breaking loop at iter  1010\n",
      "=====================RUN 202===================\n",
      "Test loss window average  0.6045184  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.53733116  increasing, breaking loop at iter  2030\n",
      "Test loss window average  2.175993  increasing, breaking loop at iter  755\n",
      "=====================RUN 203===================\n",
      "Test loss window average  0.5959204  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.56363195  increasing, breaking loop at iter  755\n",
      "Test loss window average  2.223002  increasing, breaking loop at iter  755\n",
      "=====================RUN 204===================\n",
      "Test loss window average  0.6063948  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.55067086  increasing, breaking loop at iter  1010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss window average  2.2150729  increasing, breaking loop at iter  755\n",
      "=====================RUN 205===================\n",
      "Test loss window average  0.61664563  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.54223573  increasing, breaking loop at iter  755\n",
      "Test loss window average  2.3507884  increasing, breaking loop at iter  500\n",
      "=====================RUN 206===================\n",
      "Test loss window average  0.6139293  increasing, breaking loop at iter  2540\n",
      "Test loss window average  0.53628427  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.3028212  increasing, breaking loop at iter  755\n",
      "=====================RUN 207===================\n",
      "Test loss window average  0.61230004  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.55356604  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.1937625  increasing, breaking loop at iter  1265\n",
      "=====================RUN 208===================\n",
      "Test loss window average  0.59473145  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.5246712  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.2140496  increasing, breaking loop at iter  1010\n",
      "=====================RUN 209===================\n",
      "Test loss window average  0.59382176  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.5313862  increasing, breaking loop at iter  1775\n",
      "Test loss window average  2.1554544  increasing, breaking loop at iter  500\n",
      "=====================RUN 210===================\n",
      "Test loss window average  0.61030537  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.5284063  increasing, breaking loop at iter  3815\n",
      "Test loss window average  2.3194141  increasing, breaking loop at iter  500\n",
      "=====================RUN 211===================\n",
      "Test loss window average  0.60878706  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.5495733  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.2563212  increasing, breaking loop at iter  1775\n",
      "=====================RUN 212===================\n",
      "Test loss window average  0.6146414  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.55244315  increasing, breaking loop at iter  755\n",
      "Test loss window average  2.2321496  increasing, breaking loop at iter  500\n",
      "=====================RUN 213===================\n",
      "Test loss window average  0.609206  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.5599828  increasing, breaking loop at iter  3305\n",
      "Test loss window average  2.1899014  increasing, breaking loop at iter  755\n",
      "=====================RUN 214===================\n",
      "Test loss window average  0.61645746  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.5315052  increasing, breaking loop at iter  755\n",
      "Test loss window average  2.220962  increasing, breaking loop at iter  1265\n",
      "=====================RUN 215===================\n",
      "Test loss window average  0.6111208  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.53818357  increasing, breaking loop at iter  2030\n",
      "Test loss window average  2.0982232  increasing, breaking loop at iter  1265\n",
      "=====================RUN 216===================\n",
      "Test loss window average  0.6250074  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.55519605  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.233533  increasing, breaking loop at iter  1010\n",
      "=====================RUN 217===================\n",
      "Test loss window average  0.604213  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.5562657  increasing, breaking loop at iter  1775\n",
      "Test loss window average  2.2777166  increasing, breaking loop at iter  1010\n",
      "=====================RUN 218===================\n",
      "Test loss window average  0.6176086  increasing, breaking loop at iter  2285\n",
      "Test loss window average  0.53231025  increasing, breaking loop at iter  2030\n",
      "Test loss window average  2.2858477  increasing, breaking loop at iter  1265\n",
      "=====================RUN 219===================\n",
      "Test loss window average  0.61689  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.5408836  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.2359772  increasing, breaking loop at iter  1775\n",
      "=====================RUN 220===================\n",
      "Test loss window average  0.6363974  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.5616279  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.2401943  increasing, breaking loop at iter  1010\n",
      "=====================RUN 221===================\n",
      "Test loss window average  0.60875183  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.54578376  increasing, breaking loop at iter  1775\n",
      "Test loss window average  2.1957188  increasing, breaking loop at iter  755\n",
      "=====================RUN 222===================\n",
      "Test loss window average  0.6074555  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.53542024  increasing, breaking loop at iter  755\n",
      "Test loss window average  2.246493  increasing, breaking loop at iter  755\n",
      "=====================RUN 223===================\n",
      "Test loss window average  0.63798344  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.569772  increasing, breaking loop at iter  755\n",
      "Test loss window average  2.1839495  increasing, breaking loop at iter  1265\n",
      "=====================RUN 224===================\n",
      "Test loss window average  0.6117884  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.5536056  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.1324918  increasing, breaking loop at iter  500\n",
      "=====================RUN 225===================\n",
      "Test loss window average  0.60604215  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.54939246  increasing, breaking loop at iter  1775\n",
      "Test loss window average  2.1859543  increasing, breaking loop at iter  500\n",
      "=====================RUN 226===================\n",
      "Test loss window average  0.59938765  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.5314272  increasing, breaking loop at iter  755\n",
      "Test loss window average  2.2067542  increasing, breaking loop at iter  1520\n",
      "=====================RUN 227===================\n",
      "Test loss window average  0.6376934  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.55911785  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.1948009  increasing, breaking loop at iter  500\n",
      "=====================RUN 228===================\n",
      "Test loss window average  0.6012674  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.5404013  increasing, breaking loop at iter  1775\n",
      "Test loss window average  2.2189474  increasing, breaking loop at iter  1520\n",
      "=====================RUN 229===================\n",
      "Test loss window average  0.60912496  increasing, breaking loop at iter  2030\n",
      "Test loss window average  0.5482247  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.1553664  increasing, breaking loop at iter  755\n",
      "=====================RUN 230===================\n",
      "Test loss window average  0.62182677  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.57576334  increasing, breaking loop at iter  755\n",
      "Test loss window average  2.256626  increasing, breaking loop at iter  1265\n",
      "=====================RUN 231===================\n",
      "Test loss window average  0.6056273  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.5525516  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.1976364  increasing, breaking loop at iter  1010\n",
      "=====================RUN 232===================\n",
      "Test loss window average  0.5956557  increasing, breaking loop at iter  2030\n",
      "Test loss window average  0.5352064  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.1633258  increasing, breaking loop at iter  755\n",
      "=====================RUN 233===================\n",
      "Test loss window average  0.6116663  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.53850025  increasing, breaking loop at iter  3050\n",
      "Test loss window average  2.2153094  increasing, breaking loop at iter  755\n",
      "=====================RUN 234===================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss window average  0.6208482  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.54819834  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.2080262  increasing, breaking loop at iter  500\n",
      "=====================RUN 235===================\n",
      "Test loss window average  0.6255622  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.532608  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.167303  increasing, breaking loop at iter  500\n",
      "=====================RUN 236===================\n",
      "Test loss window average  0.6240063  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.51855046  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.1697607  increasing, breaking loop at iter  500\n",
      "=====================RUN 237===================\n",
      "Test loss window average  0.5977895  increasing, breaking loop at iter  2540\n",
      "Test loss window average  0.5406382  increasing, breaking loop at iter  1775\n",
      "Test loss window average  2.2595916  increasing, breaking loop at iter  1010\n",
      "=====================RUN 238===================\n",
      "Test loss window average  0.62324536  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.54429704  increasing, breaking loop at iter  2285\n",
      "Test loss window average  2.167872  increasing, breaking loop at iter  1010\n",
      "=====================RUN 239===================\n",
      "Test loss window average  0.6013641  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.54699004  increasing, breaking loop at iter  1775\n",
      "Test loss window average  2.280963  increasing, breaking loop at iter  1775\n",
      "=====================RUN 240===================\n",
      "Test loss window average  0.6015886  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.54051304  increasing, breaking loop at iter  2540\n",
      "Test loss window average  2.1797042  increasing, breaking loop at iter  500\n",
      "=====================RUN 241===================\n",
      "Test loss window average  0.6005239  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.53943956  increasing, breaking loop at iter  755\n",
      "Test loss window average  2.2364194  increasing, breaking loop at iter  3305\n",
      "=====================RUN 242===================\n",
      "Test loss window average  0.621202  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.5438533  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.2284522  increasing, breaking loop at iter  500\n",
      "=====================RUN 243===================\n",
      "Test loss window average  0.614939  increasing, breaking loop at iter  2285\n",
      "Test loss window average  0.53334475  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.09934  increasing, breaking loop at iter  500\n",
      "=====================RUN 244===================\n",
      "Test loss window average  0.5961648  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.53668493  increasing, breaking loop at iter  2540\n",
      "Test loss window average  2.210744  increasing, breaking loop at iter  500\n",
      "=====================RUN 245===================\n",
      "Test loss window average  0.5873503  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.5342897  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.2053847  increasing, breaking loop at iter  2540\n",
      "=====================RUN 246===================\n",
      "Test loss window average  0.6105222  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.5582751  increasing, breaking loop at iter  755\n",
      "Test loss window average  2.2676878  increasing, breaking loop at iter  1010\n",
      "=====================RUN 247===================\n",
      "Test loss window average  0.6093157  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.5564711  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.148751  increasing, breaking loop at iter  755\n",
      "=====================RUN 248===================\n",
      "Test loss window average  0.61204875  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.5226562  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.164907  increasing, breaking loop at iter  2540\n",
      "=====================RUN 249===================\n",
      "Test loss window average  0.6113742  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.52965266  increasing, breaking loop at iter  755\n",
      "Test loss window average  2.195345  increasing, breaking loop at iter  500\n",
      "=====================RUN 250===================\n",
      "Test loss window average  0.60283685  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.53409564  increasing, breaking loop at iter  1775\n",
      "Test loss window average  2.2693198  increasing, breaking loop at iter  1265\n",
      "=====================RUN 251===================\n",
      "Test loss window average  0.6137345  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.5449234  increasing, breaking loop at iter  2540\n",
      "Test loss window average  2.2389517  increasing, breaking loop at iter  1010\n",
      "=====================RUN 252===================\n",
      "Test loss window average  0.62070894  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.5549673  increasing, breaking loop at iter  1775\n",
      "Test loss window average  2.19873  increasing, breaking loop at iter  500\n",
      "=====================RUN 253===================\n",
      "Test loss window average  0.6159937  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.55537975  increasing, breaking loop at iter  2795\n",
      "Test loss window average  2.1265092  increasing, breaking loop at iter  1010\n",
      "=====================RUN 254===================\n",
      "Test loss window average  0.6034783  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.55402243  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.1999507  increasing, breaking loop at iter  1010\n",
      "=====================RUN 255===================\n",
      "Test loss window average  0.6117055  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.5499687  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.2150137  increasing, breaking loop at iter  1010\n",
      "=====================RUN 256===================\n",
      "Test loss window average  0.6208583  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.5474776  increasing, breaking loop at iter  2795\n",
      "Test loss window average  2.135949  increasing, breaking loop at iter  1520\n",
      "=====================RUN 257===================\n",
      "Test loss window average  0.60902905  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.53613925  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.1310778  increasing, breaking loop at iter  500\n",
      "=====================RUN 258===================\n",
      "Test loss window average  0.60418814  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.5501646  increasing, breaking loop at iter  2030\n",
      "Test loss window average  2.223734  increasing, breaking loop at iter  500\n",
      "=====================RUN 259===================\n",
      "Test loss window average  0.6212137  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.55131155  increasing, breaking loop at iter  2030\n",
      "Test loss window average  2.13935  increasing, breaking loop at iter  500\n",
      "=====================RUN 260===================\n",
      "Test loss window average  0.62028784  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.5447881  increasing, breaking loop at iter  2795\n",
      "Test loss window average  2.2227645  increasing, breaking loop at iter  500\n",
      "=====================RUN 261===================\n",
      "Test loss window average  0.6026094  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.5499111  increasing, breaking loop at iter  2030\n",
      "Test loss window average  2.2183542  increasing, breaking loop at iter  1265\n",
      "=====================RUN 262===================\n",
      "Test loss window average  0.6142536  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.53574014  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.240089  increasing, breaking loop at iter  1265\n",
      "=====================RUN 263===================\n",
      "Test loss window average  0.6171348  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.5514204  increasing, breaking loop at iter  3815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss window average  2.3043404  increasing, breaking loop at iter  1265\n",
      "=====================RUN 264===================\n",
      "Test loss window average  0.6175328  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.56143767  increasing, breaking loop at iter  3560\n",
      "Test loss window average  2.2393026  increasing, breaking loop at iter  500\n",
      "=====================RUN 265===================\n",
      "Test loss window average  0.6250715  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.53417027  increasing, breaking loop at iter  3050\n",
      "Test loss window average  2.1830273  increasing, breaking loop at iter  755\n",
      "=====================RUN 266===================\n",
      "Test loss window average  0.6070774  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.5561699  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.249931  increasing, breaking loop at iter  500\n",
      "=====================RUN 267===================\n",
      "Test loss window average  0.6221899  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.54597145  increasing, breaking loop at iter  2030\n",
      "Test loss window average  2.1972644  increasing, breaking loop at iter  500\n",
      "=====================RUN 268===================\n",
      "Test loss window average  0.6036736  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.5643227  increasing, breaking loop at iter  755\n",
      "Test loss window average  2.2167487  increasing, breaking loop at iter  500\n",
      "=====================RUN 269===================\n",
      "Test loss window average  0.61035806  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.55129844  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.2299097  increasing, breaking loop at iter  755\n",
      "=====================RUN 270===================\n",
      "Test loss window average  0.59508  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.55801606  increasing, breaking loop at iter  2030\n",
      "Test loss window average  2.1251822  increasing, breaking loop at iter  755\n",
      "=====================RUN 271===================\n",
      "Test loss window average  0.6224153  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.54294413  increasing, breaking loop at iter  2285\n",
      "Test loss window average  2.1477022  increasing, breaking loop at iter  755\n",
      "=====================RUN 272===================\n",
      "Test loss window average  0.61745626  increasing, breaking loop at iter  2285\n",
      "Test loss window average  0.5469292  increasing, breaking loop at iter  2030\n",
      "Test loss window average  2.1894844  increasing, breaking loop at iter  1010\n",
      "=====================RUN 273===================\n",
      "Test loss window average  0.61888945  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.52838284  increasing, breaking loop at iter  2030\n",
      "Test loss window average  2.162623  increasing, breaking loop at iter  1520\n",
      "=====================RUN 274===================\n",
      "Test loss window average  0.63496536  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.5450783  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.2694433  increasing, breaking loop at iter  1010\n",
      "=====================RUN 275===================\n",
      "Test loss window average  0.6019465  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.541837  increasing, breaking loop at iter  3305\n",
      "Test loss window average  2.22792  increasing, breaking loop at iter  500\n",
      "=====================RUN 276===================\n",
      "Test loss window average  0.6027383  increasing, breaking loop at iter  2030\n",
      "Test loss window average  0.52275443  increasing, breaking loop at iter  2285\n",
      "Test loss window average  2.1675048  increasing, breaking loop at iter  1775\n",
      "=====================RUN 277===================\n",
      "Test loss window average  0.61090183  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.53162545  increasing, breaking loop at iter  755\n",
      "Test loss window average  2.2309153  increasing, breaking loop at iter  2030\n",
      "=====================RUN 278===================\n",
      "Test loss window average  0.6061734  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.5471156  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.1543348  increasing, breaking loop at iter  1265\n",
      "=====================RUN 279===================\n",
      "Test loss window average  0.61121255  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.54086083  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.2021813  increasing, breaking loop at iter  3050\n",
      "=====================RUN 280===================\n",
      "Test loss window average  0.6086762  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.52446634  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.2333899  increasing, breaking loop at iter  1775\n",
      "=====================RUN 281===================\n",
      "Test loss window average  0.6031766  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.5519613  increasing, breaking loop at iter  2540\n",
      "Test loss window average  2.1283174  increasing, breaking loop at iter  755\n",
      "=====================RUN 282===================\n",
      "Test loss window average  0.6106928  increasing, breaking loop at iter  2030\n",
      "Test loss window average  0.53665084  increasing, breaking loop at iter  1775\n",
      "Test loss window average  2.240972  increasing, breaking loop at iter  1010\n",
      "=====================RUN 283===================\n",
      "Test loss window average  0.62069947  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.56421834  increasing, breaking loop at iter  2285\n",
      "Test loss window average  2.239675  increasing, breaking loop at iter  1010\n",
      "=====================RUN 284===================\n",
      "Test loss window average  0.60570925  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.53040475  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.3379676  increasing, breaking loop at iter  1265\n",
      "=====================RUN 285===================\n",
      "Test loss window average  0.62177056  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.538111  increasing, breaking loop at iter  2030\n",
      "Test loss window average  2.1673532  increasing, breaking loop at iter  1010\n",
      "=====================RUN 286===================\n",
      "Test loss window average  0.6144315  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.56347644  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.1650987  increasing, breaking loop at iter  1010\n",
      "=====================RUN 287===================\n",
      "Test loss window average  0.600974  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.53276616  increasing, breaking loop at iter  755\n",
      "Test loss window average  2.2059712  increasing, breaking loop at iter  500\n",
      "=====================RUN 288===================\n",
      "Test loss window average  0.6202641  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.5372618  increasing, breaking loop at iter  3560\n",
      "Test loss window average  2.2076523  increasing, breaking loop at iter  755\n",
      "=====================RUN 289===================\n",
      "Test loss window average  0.60726225  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.5364959  increasing, breaking loop at iter  2540\n",
      "Test loss window average  2.155585  increasing, breaking loop at iter  1265\n",
      "=====================RUN 290===================\n",
      "Test loss window average  0.61121076  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.54643214  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.2750754  increasing, breaking loop at iter  1775\n",
      "=====================RUN 291===================\n",
      "Test loss window average  0.60907423  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.5361782  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.191974  increasing, breaking loop at iter  1520\n",
      "=====================RUN 292===================\n",
      "Test loss window average  0.6170201  increasing, breaking loop at iter  2540\n",
      "Test loss window average  0.5364296  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.2294548  increasing, breaking loop at iter  1520\n",
      "=====================RUN 293===================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss window average  0.6134844  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.5445993  increasing, breaking loop at iter  2030\n",
      "Test loss window average  2.2771564  increasing, breaking loop at iter  1520\n",
      "=====================RUN 294===================\n",
      "Test loss window average  0.605099  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.5189237  increasing, breaking loop at iter  755\n",
      "Test loss window average  2.2528226  increasing, breaking loop at iter  500\n",
      "=====================RUN 295===================\n",
      "Test loss window average  0.6128046  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.55836374  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.2504766  increasing, breaking loop at iter  2540\n",
      "=====================RUN 296===================\n",
      "Test loss window average  0.6122443  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.5259859  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.2678878  increasing, breaking loop at iter  2795\n",
      "=====================RUN 297===================\n",
      "Test loss window average  0.600655  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.5694797  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.2006211  increasing, breaking loop at iter  500\n",
      "=====================RUN 298===================\n",
      "Test loss window average  0.6115284  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.55658495  increasing, breaking loop at iter  2795\n",
      "Test loss window average  2.1908855  increasing, breaking loop at iter  500\n",
      "=====================RUN 299===================\n",
      "Test loss window average  0.6156517  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.5220804  increasing, breaking loop at iter  2285\n",
      "Test loss window average  2.2040234  increasing, breaking loop at iter  755\n",
      "=====================RUN 300===================\n",
      "Test loss window average  0.6086992  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.56090873  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.2328315  increasing, breaking loop at iter  755\n",
      "=====================RUN 301===================\n",
      "Test loss window average  0.62402076  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.5222612  increasing, breaking loop at iter  2540\n",
      "Test loss window average  2.2027917  increasing, breaking loop at iter  2030\n",
      "=====================RUN 302===================\n",
      "Test loss window average  0.617744  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.53774524  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.177929  increasing, breaking loop at iter  1520\n",
      "=====================RUN 303===================\n",
      "Test loss window average  0.6179613  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.5488928  increasing, breaking loop at iter  1775\n",
      "Test loss window average  2.1360812  increasing, breaking loop at iter  500\n",
      "=====================RUN 304===================\n",
      "Test loss window average  0.614994  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.57216763  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.1785524  increasing, breaking loop at iter  500\n",
      "=====================RUN 305===================\n",
      "Test loss window average  0.6136592  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.53792834  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.2138917  increasing, breaking loop at iter  1265\n",
      "=====================RUN 306===================\n",
      "Test loss window average  0.6101764  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.5442097  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.1592155  increasing, breaking loop at iter  1010\n",
      "=====================RUN 307===================\n",
      "Test loss window average  0.6100849  increasing, breaking loop at iter  2030\n",
      "Test loss window average  0.5490193  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.267768  increasing, breaking loop at iter  1010\n",
      "=====================RUN 308===================\n",
      "Test loss window average  0.59708315  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.529384  increasing, breaking loop at iter  3050\n",
      "Test loss window average  2.2086043  increasing, breaking loop at iter  500\n",
      "=====================RUN 309===================\n",
      "Test loss window average  0.61062944  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.54407823  increasing, breaking loop at iter  755\n",
      "Test loss window average  2.219837  increasing, breaking loop at iter  1010\n",
      "=====================RUN 310===================\n",
      "Test loss window average  0.6169205  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.53201175  increasing, breaking loop at iter  755\n",
      "Test loss window average  2.2231953  increasing, breaking loop at iter  1010\n",
      "=====================RUN 311===================\n",
      "Test loss window average  0.6132506  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.5238952  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.2570481  increasing, breaking loop at iter  500\n",
      "=====================RUN 312===================\n",
      "Test loss window average  0.59580183  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.55553705  increasing, breaking loop at iter  2030\n",
      "Test loss window average  2.1861382  increasing, breaking loop at iter  500\n",
      "=====================RUN 313===================\n",
      "Test loss window average  0.6048205  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.55330557  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.1317043  increasing, breaking loop at iter  755\n",
      "=====================RUN 314===================\n",
      "Test loss window average  0.6223994  increasing, breaking loop at iter  2030\n",
      "Test loss window average  0.53910834  increasing, breaking loop at iter  755\n",
      "Test loss window average  2.315298  increasing, breaking loop at iter  500\n",
      "=====================RUN 315===================\n",
      "Test loss window average  0.607306  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.5528607  increasing, breaking loop at iter  2540\n",
      "Test loss window average  2.118605  increasing, breaking loop at iter  500\n",
      "=====================RUN 316===================\n",
      "Test loss window average  0.60080713  increasing, breaking loop at iter  2030\n",
      "Test loss window average  0.5254784  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.2072303  increasing, breaking loop at iter  755\n",
      "=====================RUN 317===================\n",
      "Test loss window average  0.61011934  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.54659635  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.2418609  increasing, breaking loop at iter  500\n",
      "=====================RUN 318===================\n",
      "Test loss window average  0.60054046  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.531329  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.2551558  increasing, breaking loop at iter  1265\n",
      "=====================RUN 319===================\n",
      "Test loss window average  0.6196613  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.5386259  increasing, breaking loop at iter  3305\n",
      "Test loss window average  2.1814802  increasing, breaking loop at iter  500\n",
      "=====================RUN 320===================\n",
      "Test loss window average  0.5915987  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.556811  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.2490125  increasing, breaking loop at iter  3050\n",
      "=====================RUN 321===================\n",
      "Test loss window average  0.60543025  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.53332496  increasing, breaking loop at iter  755\n",
      "Test loss window average  2.2496881  increasing, breaking loop at iter  755\n",
      "=====================RUN 322===================\n",
      "Test loss window average  0.6192763  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.5522396  increasing, breaking loop at iter  3050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss window average  2.1707594  increasing, breaking loop at iter  1010\n",
      "=====================RUN 323===================\n",
      "Test loss window average  0.616087  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.54962516  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.257766  increasing, breaking loop at iter  500\n",
      "=====================RUN 324===================\n",
      "Test loss window average  0.6063077  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.5457134  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.2563922  increasing, breaking loop at iter  755\n",
      "=====================RUN 325===================\n",
      "Test loss window average  0.60599405  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.5327592  increasing, breaking loop at iter  2540\n",
      "Test loss window average  2.2227716  increasing, breaking loop at iter  1520\n",
      "=====================RUN 326===================\n",
      "Test loss window average  0.60761416  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.55803406  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.1705647  increasing, breaking loop at iter  500\n",
      "=====================RUN 327===================\n",
      "Test loss window average  0.6105786  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.5442541  increasing, breaking loop at iter  3050\n",
      "Test loss window average  2.2551327  increasing, breaking loop at iter  755\n",
      "=====================RUN 328===================\n",
      "Test loss window average  0.6206153  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.5435999  increasing, breaking loop at iter  3050\n",
      "Test loss window average  2.237105  increasing, breaking loop at iter  500\n",
      "=====================RUN 329===================\n",
      "Test loss window average  0.603115  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.5540148  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.1685727  increasing, breaking loop at iter  1010\n",
      "=====================RUN 330===================\n",
      "Test loss window average  0.60824305  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.54347926  increasing, breaking loop at iter  2540\n",
      "Test loss window average  2.1464424  increasing, breaking loop at iter  500\n",
      "=====================RUN 331===================\n",
      "Test loss window average  0.6117358  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.54691195  increasing, breaking loop at iter  755\n",
      "Test loss window average  2.294941  increasing, breaking loop at iter  500\n",
      "=====================RUN 332===================\n",
      "Test loss window average  0.62628347  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.5495177  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.2975192  increasing, breaking loop at iter  1010\n",
      "=====================RUN 333===================\n",
      "Test loss window average  0.5960259  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.54507136  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.246396  increasing, breaking loop at iter  500\n",
      "=====================RUN 334===================\n",
      "Test loss window average  0.6032388  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.5595415  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.252723  increasing, breaking loop at iter  1265\n",
      "=====================RUN 335===================\n",
      "Test loss window average  0.6014291  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.5639077  increasing, breaking loop at iter  755\n",
      "Test loss window average  2.1842728  increasing, breaking loop at iter  1520\n",
      "=====================RUN 336===================\n",
      "Test loss window average  0.6209209  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.5344737  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.2308822  increasing, breaking loop at iter  2795\n",
      "=====================RUN 337===================\n",
      "Test loss window average  0.6121199  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.5373906  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.257071  increasing, breaking loop at iter  755\n",
      "=====================RUN 338===================\n",
      "Test loss window average  0.605609  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.5285646  increasing, breaking loop at iter  3305\n",
      "Test loss window average  2.2500525  increasing, breaking loop at iter  500\n",
      "=====================RUN 339===================\n",
      "Test loss window average  0.5903503  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.54376054  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.1669896  increasing, breaking loop at iter  755\n",
      "=====================RUN 340===================\n",
      "Test loss window average  0.5916054  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.54832524  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.2444167  increasing, breaking loop at iter  755\n",
      "=====================RUN 341===================\n",
      "Test loss window average  0.60208005  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.5374944  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.145316  increasing, breaking loop at iter  1010\n",
      "=====================RUN 342===================\n",
      "Test loss window average  0.5847666  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.532149  increasing, breaking loop at iter  2030\n",
      "Test loss window average  2.1830132  increasing, breaking loop at iter  500\n",
      "=====================RUN 343===================\n",
      "Test loss window average  0.6057244  increasing, breaking loop at iter  2285\n",
      "Test loss window average  0.5671536  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.2125874  increasing, breaking loop at iter  755\n",
      "=====================RUN 344===================\n",
      "Test loss window average  0.61982757  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.51847315  increasing, breaking loop at iter  1775\n",
      "Test loss window average  2.1881914  increasing, breaking loop at iter  1265\n",
      "=====================RUN 345===================\n",
      "Test loss window average  0.6022383  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.55709505  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.2001574  increasing, breaking loop at iter  755\n",
      "=====================RUN 346===================\n",
      "Test loss window average  0.6021232  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.55459195  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.2195048  increasing, breaking loop at iter  755\n",
      "=====================RUN 347===================\n",
      "Test loss window average  0.60945505  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.5456159  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.1971445  increasing, breaking loop at iter  500\n",
      "=====================RUN 348===================\n",
      "Test loss window average  0.6239434  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.54354423  increasing, breaking loop at iter  3560\n",
      "Test loss window average  2.2002223  increasing, breaking loop at iter  755\n",
      "=====================RUN 349===================\n",
      "Test loss window average  0.6117283  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.5479813  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.195923  increasing, breaking loop at iter  1775\n",
      "=====================RUN 350===================\n",
      "Test loss window average  0.60177886  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.5430802  increasing, breaking loop at iter  2030\n",
      "Test loss window average  2.2782857  increasing, breaking loop at iter  755\n",
      "=====================RUN 351===================\n",
      "Test loss window average  0.59636706  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.5377804  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.1634989  increasing, breaking loop at iter  500\n",
      "=====================RUN 352===================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss window average  0.603834  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.55785096  increasing, breaking loop at iter  3560\n",
      "Test loss window average  2.1618757  increasing, breaking loop at iter  755\n",
      "=====================RUN 353===================\n",
      "Test loss window average  0.6138488  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.5546208  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.3089182  increasing, breaking loop at iter  1265\n",
      "=====================RUN 354===================\n",
      "Test loss window average  0.62140787  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.5580791  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.2568963  increasing, breaking loop at iter  755\n",
      "=====================RUN 355===================\n",
      "Test loss window average  0.6270622  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.5495321  increasing, breaking loop at iter  2540\n",
      "Test loss window average  2.1728394  increasing, breaking loop at iter  2030\n",
      "=====================RUN 356===================\n",
      "Test loss window average  0.6215738  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.53874147  increasing, breaking loop at iter  755\n",
      "Test loss window average  2.2491627  increasing, breaking loop at iter  2285\n",
      "=====================RUN 357===================\n",
      "Test loss window average  0.5958867  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.530926  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.3101783  increasing, breaking loop at iter  2030\n",
      "=====================RUN 358===================\n",
      "Test loss window average  0.6211299  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.5494305  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.280647  increasing, breaking loop at iter  755\n",
      "=====================RUN 359===================\n",
      "Test loss window average  0.5881757  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.5381393  increasing, breaking loop at iter  1775\n",
      "Test loss window average  2.2234313  increasing, breaking loop at iter  755\n",
      "=====================RUN 360===================\n",
      "Test loss window average  0.61274374  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.5490784  increasing, breaking loop at iter  2540\n",
      "Test loss window average  2.045702  increasing, breaking loop at iter  755\n",
      "=====================RUN 361===================\n",
      "Test loss window average  0.60831386  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.55103475  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.1904862  increasing, breaking loop at iter  500\n",
      "=====================RUN 362===================\n",
      "Test loss window average  0.6100136  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.55382437  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.1256745  increasing, breaking loop at iter  1265\n",
      "=====================RUN 363===================\n",
      "Test loss window average  0.61277145  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.56110364  increasing, breaking loop at iter  755\n",
      "Test loss window average  2.3181527  increasing, breaking loop at iter  1265\n",
      "=====================RUN 364===================\n",
      "Test loss window average  0.6144245  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.5495643  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.0950303  increasing, breaking loop at iter  755\n",
      "=====================RUN 365===================\n",
      "Test loss window average  0.6093104  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.5595428  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.1560392  increasing, breaking loop at iter  500\n",
      "=====================RUN 366===================\n",
      "Test loss window average  0.61365473  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.58056223  increasing, breaking loop at iter  755\n",
      "Test loss window average  2.2412841  increasing, breaking loop at iter  1520\n",
      "=====================RUN 367===================\n",
      "Test loss window average  0.59769875  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.53084254  increasing, breaking loop at iter  755\n",
      "Test loss window average  2.2317348  increasing, breaking loop at iter  500\n",
      "=====================RUN 368===================\n",
      "Test loss window average  0.6205055  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.54224604  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.2682333  increasing, breaking loop at iter  1010\n",
      "=====================RUN 369===================\n",
      "Test loss window average  0.622871  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.53649473  increasing, breaking loop at iter  2540\n",
      "Test loss window average  2.2303104  increasing, breaking loop at iter  1520\n",
      "=====================RUN 370===================\n",
      "Test loss window average  0.6197401  increasing, breaking loop at iter  2030\n",
      "Test loss window average  0.5429257  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.2665234  increasing, breaking loop at iter  1520\n",
      "=====================RUN 371===================\n",
      "Test loss window average  0.6097831  increasing, breaking loop at iter  2285\n",
      "Test loss window average  0.5454868  increasing, breaking loop at iter  2795\n",
      "Test loss window average  2.1828935  increasing, breaking loop at iter  500\n",
      "=====================RUN 372===================\n",
      "Test loss window average  0.598852  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.5521736  increasing, breaking loop at iter  3050\n",
      "Test loss window average  2.3549774  increasing, breaking loop at iter  755\n",
      "=====================RUN 373===================\n",
      "Test loss window average  0.6080677  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.5467702  increasing, breaking loop at iter  2795\n",
      "Test loss window average  2.200187  increasing, breaking loop at iter  755\n",
      "=====================RUN 374===================\n",
      "Test loss window average  0.61524427  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.553449  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.2457738  increasing, breaking loop at iter  1265\n",
      "=====================RUN 375===================\n",
      "Test loss window average  0.6192919  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.5433676  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.1473846  increasing, breaking loop at iter  500\n",
      "=====================RUN 376===================\n",
      "Test loss window average  0.6034235  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.5398206  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.2443957  increasing, breaking loop at iter  1520\n",
      "=====================RUN 377===================\n",
      "Test loss window average  0.6062518  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.5425345  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.2837684  increasing, breaking loop at iter  1010\n",
      "=====================RUN 378===================\n",
      "Test loss window average  0.60851884  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.5343326  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.150308  increasing, breaking loop at iter  500\n",
      "=====================RUN 379===================\n",
      "Test loss window average  0.62410223  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.535707  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.239952  increasing, breaking loop at iter  1265\n",
      "=====================RUN 380===================\n",
      "Test loss window average  0.61976665  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.5366793  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.23007  increasing, breaking loop at iter  500\n",
      "=====================RUN 381===================\n",
      "Test loss window average  0.6078165  increasing, breaking loop at iter  2030\n",
      "Test loss window average  0.53859866  increasing, breaking loop at iter  1265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss window average  2.2579093  increasing, breaking loop at iter  1265\n",
      "=====================RUN 382===================\n",
      "Test loss window average  0.60967106  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.5368133  increasing, breaking loop at iter  1775\n",
      "Test loss window average  2.1929307  increasing, breaking loop at iter  755\n",
      "=====================RUN 383===================\n",
      "Test loss window average  0.6042847  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.53363377  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.1731305  increasing, breaking loop at iter  755\n",
      "=====================RUN 384===================\n",
      "Test loss window average  0.6136866  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.54470474  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.1447234  increasing, breaking loop at iter  2030\n",
      "=====================RUN 385===================\n",
      "Test loss window average  0.61992604  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.55830646  increasing, breaking loop at iter  2285\n",
      "Test loss window average  2.1490617  increasing, breaking loop at iter  500\n",
      "=====================RUN 386===================\n",
      "Test loss window average  0.6117094  increasing, breaking loop at iter  2030\n",
      "Test loss window average  0.5533096  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.2455592  increasing, breaking loop at iter  2030\n",
      "=====================RUN 387===================\n",
      "Test loss window average  0.6271382  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.5698777  increasing, breaking loop at iter  2285\n",
      "Test loss window average  2.2915177  increasing, breaking loop at iter  1265\n",
      "=====================RUN 388===================\n",
      "Test loss window average  0.60663015  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.52817905  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.1926088  increasing, breaking loop at iter  1010\n",
      "=====================RUN 389===================\n",
      "Test loss window average  0.6121855  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.5517486  increasing, breaking loop at iter  1775\n",
      "Test loss window average  2.205231  increasing, breaking loop at iter  500\n",
      "=====================RUN 390===================\n",
      "Test loss window average  0.62762874  increasing, breaking loop at iter  2030\n",
      "Test loss window average  0.55401886  increasing, breaking loop at iter  1775\n",
      "Test loss window average  2.258869  increasing, breaking loop at iter  755\n",
      "=====================RUN 391===================\n",
      "Test loss window average  0.61452204  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.53652984  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.2593846  increasing, breaking loop at iter  755\n",
      "=====================RUN 392===================\n",
      "Test loss window average  0.61380625  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.514494  increasing, breaking loop at iter  1775\n",
      "Test loss window average  2.1216252  increasing, breaking loop at iter  2030\n",
      "=====================RUN 393===================\n",
      "Test loss window average  0.6055224  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.53912425  increasing, breaking loop at iter  755\n",
      "Test loss window average  2.1603138  increasing, breaking loop at iter  500\n",
      "=====================RUN 394===================\n",
      "Test loss window average  0.615009  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.5504817  increasing, breaking loop at iter  1775\n",
      "Test loss window average  2.2623315  increasing, breaking loop at iter  2030\n",
      "=====================RUN 395===================\n",
      "Test loss window average  0.6242963  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.5496418  increasing, breaking loop at iter  755\n",
      "Test loss window average  2.2074387  increasing, breaking loop at iter  1010\n",
      "=====================RUN 396===================\n",
      "Test loss window average  0.61419266  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.5377929  increasing, breaking loop at iter  2795\n",
      "Test loss window average  2.2383943  increasing, breaking loop at iter  755\n",
      "=====================RUN 397===================\n",
      "Test loss window average  0.61180264  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.5510421  increasing, breaking loop at iter  3560\n",
      "Test loss window average  2.1957974  increasing, breaking loop at iter  500\n",
      "=====================RUN 398===================\n",
      "Test loss window average  0.6054162  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.5385972  increasing, breaking loop at iter  755\n",
      "Test loss window average  2.2575643  increasing, breaking loop at iter  1520\n",
      "=====================RUN 399===================\n",
      "Test loss window average  0.5951968  increasing, breaking loop at iter  2285\n",
      "Test loss window average  0.54966354  increasing, breaking loop at iter  3815\n",
      "Test loss window average  2.2414773  increasing, breaking loop at iter  755\n",
      "=====================RUN 400===================\n",
      "Test loss window average  0.60908556  increasing, breaking loop at iter  2030\n",
      "Test loss window average  0.5380226  increasing, breaking loop at iter  755\n",
      "Test loss window average  2.2183776  increasing, breaking loop at iter  1265\n",
      "=====================RUN 401===================\n",
      "Test loss window average  0.60363394  increasing, breaking loop at iter  2285\n",
      "Test loss window average  0.54063845  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.2123713  increasing, breaking loop at iter  1265\n",
      "=====================RUN 402===================\n",
      "Test loss window average  0.606622  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.55989546  increasing, breaking loop at iter  1775\n",
      "Test loss window average  2.2423623  increasing, breaking loop at iter  755\n",
      "=====================RUN 403===================\n",
      "Test loss window average  0.61143255  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.5410401  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.2667768  increasing, breaking loop at iter  2030\n",
      "=====================RUN 404===================\n",
      "Test loss window average  0.61102337  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.525937  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.1328766  increasing, breaking loop at iter  1265\n",
      "=====================RUN 405===================\n",
      "Test loss window average  0.59984213  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.55740166  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.1452243  increasing, breaking loop at iter  500\n",
      "=====================RUN 406===================\n",
      "Test loss window average  0.6078861  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.5520075  increasing, breaking loop at iter  755\n",
      "Test loss window average  2.232465  increasing, breaking loop at iter  1265\n",
      "=====================RUN 407===================\n",
      "Test loss window average  0.6072576  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.5572128  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.2471595  increasing, breaking loop at iter  755\n",
      "=====================RUN 408===================\n",
      "Test loss window average  0.5999708  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.5597806  increasing, breaking loop at iter  755\n",
      "Test loss window average  2.2966535  increasing, breaking loop at iter  755\n",
      "=====================RUN 409===================\n",
      "Test loss window average  0.61917037  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.5606852  increasing, breaking loop at iter  2540\n",
      "Test loss window average  2.1843324  increasing, breaking loop at iter  500\n",
      "=====================RUN 410===================\n",
      "Test loss window average  0.624958  increasing, breaking loop at iter  500\n",
      "Test loss window average  0.5604966  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.3067164  increasing, breaking loop at iter  1010\n",
      "=====================RUN 411===================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss window average  0.58978146  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.5320094  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.2846253  increasing, breaking loop at iter  1520\n",
      "=====================RUN 412===================\n",
      "Test loss window average  0.59851766  increasing, breaking loop at iter  2030\n",
      "Test loss window average  0.5489866  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.2056844  increasing, breaking loop at iter  1520\n",
      "=====================RUN 413===================\n",
      "Test loss window average  0.61440486  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.5360476  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.210052  increasing, breaking loop at iter  1520\n",
      "=====================RUN 414===================\n",
      "Test loss window average  0.6052676  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.522014  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.1752894  increasing, breaking loop at iter  500\n",
      "=====================RUN 415===================\n",
      "Test loss window average  0.5875306  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.5245279  increasing, breaking loop at iter  2030\n",
      "Test loss window average  2.1582317  increasing, breaking loop at iter  755\n",
      "=====================RUN 416===================\n",
      "Test loss window average  0.609694  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.5801361  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.2498434  increasing, breaking loop at iter  4325\n",
      "=====================RUN 417===================\n",
      "Test loss window average  0.620693  increasing, breaking loop at iter  2030\n",
      "Test loss window average  0.5539793  increasing, breaking loop at iter  3305\n",
      "Test loss window average  2.213645  increasing, breaking loop at iter  755\n",
      "=====================RUN 418===================\n",
      "Test loss window average  0.61065286  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.53712934  increasing, breaking loop at iter  1775\n",
      "Test loss window average  2.248951  increasing, breaking loop at iter  1520\n",
      "=====================RUN 419===================\n",
      "Test loss window average  0.59888613  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.546259  increasing, breaking loop at iter  3305\n",
      "Test loss window average  2.235912  increasing, breaking loop at iter  500\n",
      "=====================RUN 420===================\n",
      "Test loss window average  0.5993368  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.5375269  increasing, breaking loop at iter  2795\n",
      "Test loss window average  2.1973019  increasing, breaking loop at iter  1775\n",
      "=====================RUN 421===================\n",
      "Test loss window average  0.6141267  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.5483725  increasing, breaking loop at iter  2540\n",
      "Test loss window average  2.1197088  increasing, breaking loop at iter  755\n",
      "=====================RUN 422===================\n",
      "Test loss window average  0.62544954  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.5481974  increasing, breaking loop at iter  2285\n",
      "Test loss window average  2.1989582  increasing, breaking loop at iter  755\n",
      "=====================RUN 423===================\n",
      "Test loss window average  0.61625504  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.5308261  increasing, breaking loop at iter  3815\n",
      "Test loss window average  2.2733078  increasing, breaking loop at iter  755\n",
      "=====================RUN 424===================\n",
      "Test loss window average  0.60064703  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.5622416  increasing, breaking loop at iter  3050\n",
      "Test loss window average  2.2443502  increasing, breaking loop at iter  500\n",
      "=====================RUN 425===================\n",
      "Test loss window average  0.59531546  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.55069685  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.1919508  increasing, breaking loop at iter  1265\n",
      "=====================RUN 426===================\n",
      "Test loss window average  0.61648333  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.54468316  increasing, breaking loop at iter  3305\n",
      "Test loss window average  2.2006936  increasing, breaking loop at iter  500\n",
      "=====================RUN 427===================\n",
      "Test loss window average  0.60605097  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.55246216  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.3188534  increasing, breaking loop at iter  1265\n",
      "=====================RUN 428===================\n",
      "Test loss window average  0.61645794  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.5261038  increasing, breaking loop at iter  5090\n",
      "Test loss window average  2.162374  increasing, breaking loop at iter  755\n",
      "=====================RUN 429===================\n",
      "Test loss window average  0.6169956  increasing, breaking loop at iter  2285\n",
      "Test loss window average  0.5318836  increasing, breaking loop at iter  2030\n",
      "Test loss window average  2.1468732  increasing, breaking loop at iter  2285\n",
      "=====================RUN 430===================\n",
      "Test loss window average  0.60977054  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.5576548  increasing, breaking loop at iter  1775\n",
      "Test loss window average  2.2147932  increasing, breaking loop at iter  500\n",
      "=====================RUN 431===================\n",
      "Test loss window average  0.6106014  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.52214766  increasing, breaking loop at iter  2030\n",
      "Test loss window average  2.2426074  increasing, breaking loop at iter  500\n",
      "=====================RUN 432===================\n",
      "Test loss window average  0.59655714  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.5329849  increasing, breaking loop at iter  2285\n",
      "Test loss window average  2.275789  increasing, breaking loop at iter  755\n",
      "=====================RUN 433===================\n",
      "Test loss window average  0.6069981  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.5552264  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.2583857  increasing, breaking loop at iter  1010\n",
      "=====================RUN 434===================\n",
      "Test loss window average  0.6361454  increasing, breaking loop at iter  500\n",
      "Test loss window average  0.52192396  increasing, breaking loop at iter  755\n",
      "Test loss window average  2.1844354  increasing, breaking loop at iter  1265\n",
      "=====================RUN 435===================\n",
      "Test loss window average  0.61552083  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.5454859  increasing, breaking loop at iter  2285\n",
      "Test loss window average  2.1862886  increasing, breaking loop at iter  1010\n",
      "=====================RUN 436===================\n",
      "Test loss window average  0.6091996  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.5565426  increasing, breaking loop at iter  2285\n",
      "Test loss window average  2.242894  increasing, breaking loop at iter  1010\n",
      "=====================RUN 437===================\n",
      "Test loss window average  0.6075436  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.555134  increasing, breaking loop at iter  2030\n",
      "Test loss window average  2.2558897  increasing, breaking loop at iter  755\n",
      "=====================RUN 438===================\n",
      "Test loss window average  0.60370594  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.5216719  increasing, breaking loop at iter  755\n",
      "Test loss window average  2.2371187  increasing, breaking loop at iter  1775\n",
      "=====================RUN 439===================\n",
      "Test loss window average  0.6134224  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.54819787  increasing, breaking loop at iter  755\n",
      "Test loss window average  2.2812243  increasing, breaking loop at iter  500\n",
      "=====================RUN 440===================\n",
      "Test loss window average  0.5945466  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.53752863  increasing, breaking loop at iter  1520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss window average  2.2946403  increasing, breaking loop at iter  755\n",
      "=====================RUN 441===================\n",
      "Test loss window average  0.60827845  increasing, breaking loop at iter  2540\n",
      "Test loss window average  0.5682871  increasing, breaking loop at iter  3050\n",
      "Test loss window average  2.2231894  increasing, breaking loop at iter  755\n",
      "=====================RUN 442===================\n",
      "Test loss window average  0.6094687  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.55353075  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.2203176  increasing, breaking loop at iter  2030\n",
      "=====================RUN 443===================\n",
      "Test loss window average  0.61452544  increasing, breaking loop at iter  2030\n",
      "Test loss window average  0.5505024  increasing, breaking loop at iter  1775\n",
      "Test loss window average  2.2141585  increasing, breaking loop at iter  1010\n",
      "=====================RUN 444===================\n",
      "Test loss window average  0.59562224  increasing, breaking loop at iter  2285\n",
      "Test loss window average  0.53449243  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.3192456  increasing, breaking loop at iter  500\n",
      "=====================RUN 445===================\n",
      "Test loss window average  0.61017865  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.5627603  increasing, breaking loop at iter  1775\n",
      "Test loss window average  2.0969787  increasing, breaking loop at iter  755\n",
      "=====================RUN 446===================\n",
      "Test loss window average  0.6085104  increasing, breaking loop at iter  2285\n",
      "Test loss window average  0.5654588  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.245634  increasing, breaking loop at iter  755\n",
      "=====================RUN 447===================\n",
      "Test loss window average  0.6152947  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.538826  increasing, breaking loop at iter  3560\n",
      "Test loss window average  2.149404  increasing, breaking loop at iter  1010\n",
      "=====================RUN 448===================\n",
      "Test loss window average  0.6063414  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.5373878  increasing, breaking loop at iter  2540\n",
      "Test loss window average  2.17828  increasing, breaking loop at iter  1775\n",
      "=====================RUN 449===================\n",
      "Test loss window average  0.6042959  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.55810964  increasing, breaking loop at iter  2030\n",
      "Test loss window average  2.201521  increasing, breaking loop at iter  500\n",
      "=====================RUN 450===================\n",
      "Test loss window average  0.60238636  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.5498178  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.1402364  increasing, breaking loop at iter  755\n",
      "=====================RUN 451===================\n",
      "Test loss window average  0.619364  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.54323137  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.192878  increasing, breaking loop at iter  755\n",
      "=====================RUN 452===================\n",
      "Test loss window average  0.6097586  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.538652  increasing, breaking loop at iter  1775\n",
      "Test loss window average  2.2031624  increasing, breaking loop at iter  500\n",
      "=====================RUN 453===================\n",
      "Test loss window average  0.6139606  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.5582197  increasing, breaking loop at iter  3050\n",
      "Test loss window average  2.190192  increasing, breaking loop at iter  755\n",
      "=====================RUN 454===================\n",
      "Test loss window average  0.62739974  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.54611456  increasing, breaking loop at iter  3305\n",
      "Test loss window average  2.22975  increasing, breaking loop at iter  500\n",
      "=====================RUN 455===================\n",
      "Test loss window average  0.5990141  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.55405325  increasing, breaking loop at iter  1775\n",
      "Test loss window average  2.2753775  increasing, breaking loop at iter  755\n",
      "=====================RUN 456===================\n",
      "Test loss window average  0.6088928  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.5611457  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.2393894  increasing, breaking loop at iter  1265\n",
      "=====================RUN 457===================\n",
      "Test loss window average  0.61059606  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.5440399  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.144168  increasing, breaking loop at iter  1265\n",
      "=====================RUN 458===================\n",
      "Test loss window average  0.6035747  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.55170476  increasing, breaking loop at iter  2030\n",
      "Test loss window average  2.1799662  increasing, breaking loop at iter  1010\n",
      "=====================RUN 459===================\n",
      "Test loss window average  0.62047136  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.5541898  increasing, breaking loop at iter  2540\n",
      "Test loss window average  2.1635804  increasing, breaking loop at iter  500\n",
      "=====================RUN 460===================\n",
      "Test loss window average  0.6077989  increasing, breaking loop at iter  2030\n",
      "Test loss window average  0.5350999  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.256341  increasing, breaking loop at iter  1010\n",
      "=====================RUN 461===================\n",
      "Test loss window average  0.5990638  increasing, breaking loop at iter  2030\n",
      "Test loss window average  0.53102183  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.1351948  increasing, breaking loop at iter  500\n",
      "=====================RUN 462===================\n",
      "Test loss window average  0.59496886  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.5311205  increasing, breaking loop at iter  2540\n",
      "Test loss window average  2.2751799  increasing, breaking loop at iter  755\n",
      "=====================RUN 463===================\n",
      "Test loss window average  0.6043668  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.5324816  increasing, breaking loop at iter  2540\n",
      "Test loss window average  2.214984  increasing, breaking loop at iter  500\n",
      "=====================RUN 464===================\n",
      "Test loss window average  0.6169944  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.5274529  increasing, breaking loop at iter  3305\n",
      "Test loss window average  2.1366563  increasing, breaking loop at iter  500\n",
      "=====================RUN 465===================\n",
      "Test loss window average  0.6040708  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.5417968  increasing, breaking loop at iter  755\n",
      "Test loss window average  2.2173915  increasing, breaking loop at iter  755\n",
      "=====================RUN 466===================\n",
      "Test loss window average  0.61623985  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.54513097  increasing, breaking loop at iter  2795\n",
      "Test loss window average  2.2294712  increasing, breaking loop at iter  500\n",
      "=====================RUN 467===================\n",
      "Test loss window average  0.61331457  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.53893316  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.234925  increasing, breaking loop at iter  2030\n",
      "=====================RUN 468===================\n",
      "Test loss window average  0.5968557  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.52644724  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.2224774  increasing, breaking loop at iter  1010\n",
      "=====================RUN 469===================\n",
      "Test loss window average  0.5972438  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.56404144  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.1976814  increasing, breaking loop at iter  500\n",
      "=====================RUN 470===================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss window average  0.6097024  increasing, breaking loop at iter  2285\n",
      "Test loss window average  0.5635973  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.3414776  increasing, breaking loop at iter  1775\n",
      "=====================RUN 471===================\n",
      "Test loss window average  0.60692257  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.5575054  increasing, breaking loop at iter  3050\n",
      "Test loss window average  2.1959612  increasing, breaking loop at iter  755\n",
      "=====================RUN 472===================\n",
      "Test loss window average  0.6091249  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.5519213  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.1686969  increasing, breaking loop at iter  755\n",
      "=====================RUN 473===================\n",
      "Test loss window average  0.60255903  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.5286772  increasing, breaking loop at iter  2030\n",
      "Test loss window average  2.1694336  increasing, breaking loop at iter  1265\n",
      "=====================RUN 474===================\n",
      "Test loss window average  0.6173904  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.54203135  increasing, breaking loop at iter  2030\n",
      "Test loss window average  2.1258986  increasing, breaking loop at iter  755\n",
      "=====================RUN 475===================\n",
      "Test loss window average  0.6108445  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.5323203  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.256895  increasing, breaking loop at iter  1010\n",
      "=====================RUN 476===================\n",
      "Test loss window average  0.6202534  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.5493558  increasing, breaking loop at iter  755\n",
      "Test loss window average  2.2773926  increasing, breaking loop at iter  1265\n",
      "=====================RUN 477===================\n",
      "Test loss window average  0.6076025  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.5272758  increasing, breaking loop at iter  1775\n",
      "Test loss window average  2.2468708  increasing, breaking loop at iter  755\n",
      "=====================RUN 478===================\n",
      "Test loss window average  0.6129598  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.5279934  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.1687653  increasing, breaking loop at iter  1520\n",
      "=====================RUN 479===================\n",
      "Test loss window average  0.6277131  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.563516  increasing, breaking loop at iter  2030\n",
      "Test loss window average  2.1963708  increasing, breaking loop at iter  2030\n",
      "=====================RUN 480===================\n",
      "Test loss window average  0.6127467  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.53502256  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.1975307  increasing, breaking loop at iter  1775\n",
      "=====================RUN 481===================\n",
      "Test loss window average  0.5989382  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.5507015  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.2731512  increasing, breaking loop at iter  500\n",
      "=====================RUN 482===================\n",
      "Test loss window average  0.6153019  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.51770383  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.1492229  increasing, breaking loop at iter  1520\n",
      "=====================RUN 483===================\n",
      "Test loss window average  0.6240997  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.5613769  increasing, breaking loop at iter  2030\n",
      "Test loss window average  2.174706  increasing, breaking loop at iter  500\n",
      "=====================RUN 484===================\n",
      "Test loss window average  0.6266077  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.5432407  increasing, breaking loop at iter  1010\n",
      "Test loss window average  2.1199267  increasing, breaking loop at iter  500\n",
      "=====================RUN 485===================\n",
      "Test loss window average  0.59500265  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.532683  increasing, breaking loop at iter  1775\n",
      "Test loss window average  2.1943383  increasing, breaking loop at iter  500\n",
      "=====================RUN 486===================\n",
      "Test loss window average  0.62469196  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.544077  increasing, breaking loop at iter  4325\n",
      "Test loss window average  2.2638555  increasing, breaking loop at iter  500\n",
      "=====================RUN 487===================\n",
      "Test loss window average  0.6072117  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.5444363  increasing, breaking loop at iter  1520\n",
      "Test loss window average  2.2299104  increasing, breaking loop at iter  2030\n",
      "=====================RUN 488===================\n",
      "Test loss window average  0.6048168  increasing, breaking loop at iter  755\n",
      "Test loss window average  0.54619783  increasing, breaking loop at iter  1775\n",
      "Test loss window average  2.2673042  increasing, breaking loop at iter  755\n",
      "=====================RUN 489===================\n",
      "Test loss window average  0.61200297  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.5393251  increasing, breaking loop at iter  2285\n",
      "Test loss window average  2.164849  increasing, breaking loop at iter  1775\n",
      "=====================RUN 490===================\n",
      "Test loss window average  0.61598563  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.56693256  increasing, breaking loop at iter  755\n",
      "Test loss window average  2.2748272  increasing, breaking loop at iter  1010\n",
      "=====================RUN 491===================\n",
      "Test loss window average  0.5996156  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.54582983  increasing, breaking loop at iter  3305\n",
      "Test loss window average  2.196525  increasing, breaking loop at iter  500\n",
      "=====================RUN 492===================\n",
      "Test loss window average  0.6150305  increasing, breaking loop at iter  1010\n",
      "Test loss window average  0.543932  increasing, breaking loop at iter  1265\n",
      "Test loss window average  2.2454863  increasing, breaking loop at iter  1265\n",
      "=====================RUN 493===================\n",
      "Test loss window average  0.60900205  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.54670477  increasing, breaking loop at iter  4580\n",
      "Test loss window average  2.255114  increasing, breaking loop at iter  500\n",
      "=====================RUN 494===================\n",
      "Test loss window average  0.6083636  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.54258394  increasing, breaking loop at iter  1775\n",
      "Test loss window average  2.1829257  increasing, breaking loop at iter  755\n",
      "=====================RUN 495===================\n",
      "Test loss window average  0.62090313  increasing, breaking loop at iter  2030\n",
      "Test loss window average  0.5661961  increasing, breaking loop at iter  3050\n",
      "Test loss window average  2.2298238  increasing, breaking loop at iter  755\n",
      "=====================RUN 496===================\n",
      "Test loss window average  0.6110166  increasing, breaking loop at iter  1775\n",
      "Test loss window average  0.538253  increasing, breaking loop at iter  3050\n",
      "Test loss window average  2.1019812  increasing, breaking loop at iter  755\n",
      "=====================RUN 497===================\n",
      "Test loss window average  0.6139997  increasing, breaking loop at iter  2030\n",
      "Test loss window average  0.5525539  increasing, breaking loop at iter  2540\n",
      "Test loss window average  2.180608  increasing, breaking loop at iter  500\n",
      "=====================RUN 498===================\n",
      "Test loss window average  0.6128352  increasing, breaking loop at iter  1520\n",
      "Test loss window average  0.5446723  increasing, breaking loop at iter  3560\n",
      "Test loss window average  2.1647112  increasing, breaking loop at iter  500\n",
      "=====================RUN 499===================\n",
      "Test loss window average  0.6104626  increasing, breaking loop at iter  1265\n",
      "Test loss window average  0.5363844  increasing, breaking loop at iter  755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss window average  2.1576688  increasing, breaking loop at iter  500\n"
     ]
    }
   ],
   "source": [
    "print('Best Q params:', qbest_params)\n",
    "print('Best G params:', gbest_params)\n",
    "N = 10000\n",
    "seed = 0\n",
    "num_runs = 500\n",
    "\n",
    "output_type_Q = 'categorical'\n",
    "output_size_Q = 1\n",
    "output_type_G = 'categorical'\n",
    "output_size_G = 1\n",
    "input_size_Q = z.shape[-1] + 1  # we will concatenate the treatment var inside the qnet class\n",
    "input_size_G = z.shape[-1]\n",
    "qlayers = qbest_params['layers']\n",
    "qdropout = qbest_params['dropout']\n",
    "qlayer_size = qbest_params['layer_size']\n",
    "qiters = 100000  # use the early stopping iter\n",
    "qlr = qbest_params['lr']\n",
    "beta = qbest_params['beta']\n",
    "qbatch_size = qbest_params['batch_size']\n",
    "\n",
    "glayers = gbest_params['layers']\n",
    "gdropout = gbest_params['dropout']\n",
    "glayer_size = gbest_params['layer_size']\n",
    "giters = 100000  # use the early stopping iter\n",
    "glr = gbest_params['lr']\n",
    "gbatch_size = gbest_params['batch_size']\n",
    "\n",
    "estimates_naive = []\n",
    "estimates_upd_treg = []\n",
    "eps_ = []\n",
    "for i in range(num_runs):\n",
    "    print('=====================RUN {}==================='.format(i))\n",
    "    seed += 1\n",
    "    # data generation:\n",
    "    z, x, y, _, _ = generate_data(N, seed=seed)\n",
    "    x = torch.tensor(x).type(torch.float32)\n",
    "    z = torch.tensor(z).type(torch.float32)\n",
    "    y = torch.tensor(y).type(torch.float32)\n",
    "    x_int1 = torch.ones_like(x)  # this is the 'intervention data'\n",
    "    x_int0 = torch.zeros_like(x)    \n",
    "    \n",
    "\n",
    "    qnet = QNet(input_size=input_size_Q, num_layers=qlayers,\n",
    "                          layers_size=qlayer_size, output_size=output_size_Q,\n",
    "                         output_type=output_type_Q, dropout=qdropout)\n",
    "\n",
    "    gnet = GNet(input_size=input_size_G, num_layers=glayers,\n",
    "                          layers_size=glayer_size, output_size=output_size_G,\n",
    "                         output_type=output_type_G, dropout=gdropout)\n",
    "    \n",
    "    # def G trainer\n",
    "    gtrainer = Trainer(net=gnet, net_type='G', beta=beta, iterations=giters, outcome_type=output_type_G,\n",
    "                  batch_size=gbatch_size, test_iter=5, lr=glr)\n",
    "    # train G\n",
    "    train_loss_g_, val_loss_g_, stop_it_g, best_model_g, best_model_test_loss_g, eps = gtrainer.train(x, y, z)\n",
    "    # Get x_preds from G\n",
    "    _, x_pred = gtrainer.test(best_model_g, x, y, z)\n",
    "    # def Q trainer (no treg)\n",
    "    qtrainer = Trainer(net=qnet, net_type='Q',  beta=0.0, iterations=qiters, outcome_type=output_type_Q,\n",
    "                  batch_size=qbatch_size, test_iter=5, lr=qlr)\n",
    "    # train Q  (no treg)\n",
    "    train_loss_q_,  val_loss_q_, stop_it_q, best_model_q, best_model_test_loss_q, eps = qtrainer.train(x,\n",
    "                                                                                                  y, z, x_pred=x_pred)\n",
    "    eps_.append(eps)\n",
    "    # generate counterfactual preds (no treg)\n",
    "    _,  Q1 = qtrainer.test(best_model_q, x_int1, y, z, x_pred)\n",
    "    _, Q0 = qtrainer.test(best_model_q, x_int0, y, z, x_pred)\n",
    "    Q1 = Q1.detach().numpy()\n",
    "    Q0 = Q0.detach().numpy()\n",
    "\n",
    "    # record initial estimate\n",
    "    biased_psi = (Q1 - Q0).mean()\n",
    "    estimates_naive.append(biased_psi)\n",
    "    \n",
    "    # redefine Q trainer (treg enabled)\n",
    "    qtrainer = Trainer(net=qnet, net_type='Q',  beta=beta, iterations=qiters, outcome_type=output_type_Q,\n",
    "                  batch_size=qbatch_size, test_iter=5, lr=qlr)\n",
    "    # retrain Q using same x_preds\n",
    "    train_loss_q_,  val_loss_q_, stop_it_q, best_model_q, best_model_test_loss_q, eps = qtrainer.train(x,y, z, x_pred=x_pred)\n",
    "\n",
    "    # generate counterfactual preds (treg enabled)\n",
    "    _,  Q1 = qtrainer.test(best_model_q, x_int1, y, z, x_pred)\n",
    "    _, Q0 = qtrainer.test(best_model_q, x_int0, y, z, x_pred)\n",
    "    Q1 = Q1.detach().numpy()\n",
    "    Q0 = Q0.detach().numpy()\n",
    "        \n",
    "    # record updated estimate\n",
    "    upd_psi_treg = (Q1 - Q0).mean()\n",
    "    estimates_upd_treg.append(upd_psi_treg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e37c9e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============TREG==============\n",
      "True psi:  0.1956508\n",
      "naive psi:  0.20918414  relative bias: 6.917089000895834 %\n",
      "updated TMLE psi:  0.20671476  relative bias: 5.654954765022098 %\n",
      "Reduction in bias: 1.2621342358737362 %\n",
      "naive psi var: 0.0008140965\n",
      "updated psi var: 0.000746003\n",
      "Average of reductions: 0.7958621 %\n"
     ]
    }
   ],
   "source": [
    "print('============TREG==============')\n",
    "      \n",
    "estimates_upd_treg = np.asarray(estimates_upd_treg)\n",
    "estimates_naive = np.asarray(estimates_naive)\n",
    "\n",
    "print('True psi: ', true_psi)\n",
    "print('naive psi: ', estimates_naive.mean(), ' relative bias:',\n",
    "      (estimates_naive.mean() - true_psi)/true_psi * 100, '%')\n",
    "print('updated TMLE psi: ', estimates_upd_treg.mean(), ' relative bias:',\n",
    "      (estimates_upd_treg.mean() - true_psi)/true_psi * 100, '%')\n",
    "print('Reduction in bias:', np.abs(estimates_naive.mean() - true_psi)/true_psi * 100 - \n",
    "     np.abs(estimates_upd_treg.mean() - true_psi)/true_psi * 100, '%')\n",
    "\n",
    "# This takes the reduction in relative bias for each simulation first, then takes an average\n",
    "# (Owing to the nonlinearity of the ||x|| function, this gives different results which are\n",
    "# worth considering.)\n",
    "print('naive psi var:', estimates_naive.var())\n",
    "print('updated psi var:', estimates_upd_treg.var())\n",
    "errors_naive = (estimates_naive - true_psi)/true_psi *100\n",
    "errors_updated = (estimates_upd_treg - true_psi)/true_psi *100\n",
    "diff_errors = np.abs(errors_naive) - np.abs(errors_updated)\n",
    "print('Average of reductions:', diff_errors.mean(), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c3d5d74f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.60635227, dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(np.asarray(val_loss_g_))\n",
    "best_model_test_loss_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fef13a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(2.149334, dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(np.asarray(val_loss_q_))\n",
    "best_model_test_loss_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0eca62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832b57e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03db0ad8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1f47f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
